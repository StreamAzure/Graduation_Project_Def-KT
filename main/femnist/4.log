2023-04-22 08:56:47,535 [MainThread] [INFO ]  Configurations: {'task_id': '', 'data': {'root': '../data/', 'dataset': 'femnist', 'split_type': 'niid', 'min_size': 10, 'data_amount': 0.05, 'iid_fraction': 0.1, 'user': False, 'train_test_split': 0.9, 'class_per_client': 1, 'num_of_clients': 100, 'alpha': 0.2, 'weights': None}, 'model': 'simple_cnn', 'test_mode': 'test_in_client', 'test_method': 'average', 'server': {'track': False, 'rounds': 5000, 'clients_per_round': 20, 'test_every': 1, 'save_model_every': 10, 'save_model_path': '', 'batch_size': 64, 'test_all': True, 'random_selection': True, 'aggregation_stragtegy': 'FedAvg', 'aggregation_content': 'all'}, 'client': {'track': False, 'batch_size': 16, 'test_batch_size': 5, 'local_epoch': 20, 'optimizer': {'type': 'SGD', 'lr': 0.01, 'momentum': 0.5, 'weight_decay': 0.0005, 'nesterov': True}, 'seed': 0, 'local_test': True}, 'gpu': 1, 'distributed': {'backend': 'nccl', 'init_method': '', 'world_size': 0, 'rank': 0, 'local_rank': 0}, 'tracking': {'database': '', 'log_file': '', 'log_level': 'INFO', 'metric_file': '', 'save_every': 1}, 'resource_heterogeneous': {'simulate': False, 'hetero_type': 'real', 'level': 3, 'sleep_group_num': 1000, 'total_time': 1000, 'fraction': 1, 'grouping_strategy': 'greedy', 'initial_default_time': 5, 'default_time_momentum': 0.2}, 'seed': 0, 'is_distributed': False, 'device': 0}
2023-04-22 08:56:52,467 [MainThread] [INFO ]  Total training data amount: 35507
2023-04-22 08:56:52,467 [MainThread] [INFO ]  Total testing data amount: 4045
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
local_batch_size: 1024, DML_batch_size: 16, local_epoch: 5, DML_epoch: 15, alpha: 1, beta: 1, DML_lr: 0.015
2023-04-22 08:56:52,719 [MainThread] [INFO ]  Clients in total: 186
2023-04-22 08:56:52,754 [MainThread] [INFO ]  
-------- round 0 --------
2023-04-22 08:56:52,754 [MainThread] [INFO ]  --- start training ---
/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/datasets/dataset.py:161: UserWarning: you are shuffling a 'Tensor' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.
  np.random.shuffle(data_x)
/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/datasets/dataset.py:163: UserWarning: you are shuffling a 'Tensor' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.
  np.random.shuffle(data_y)
client: f2178_93
--- local_update_loss : 4.14
client: f0885_39
--- local_update_loss : 4.13
client: f3616_07
--- local_update_loss : 4.10
client: f1369_36
--- local_update_loss : 4.14
client: f3251_33
--- local_update_loss : 4.12
client: f1431_47
--- local_update_loss : 4.15
client: f0337_24
--- local_update_loss : 4.12
client: f2238_86
--- local_update_loss : 4.13
client: f3350_11
--- local_update_loss : 4.12
client: f0190_12
--- local_update_loss : 4.13
client: f0180_29
--- local_update_loss : 4.12
client: f3675_24
--- local_update_loss : 4.14
client: f3519_18
--- local_update_loss : 4.12
client: f3938_46
--- local_update_loss : 4.12
client: f2337_71
--- local_update_loss : 4.12
client: f1929_04
--- local_update_loss : 4.15
client: f0733_34
--- local_update_loss : 4.12
client: f1779_01
--- local_update_loss : 4.12
client: f3219_49
--- local_update_loss : 4.13
client: f2506_77
--- local_update_loss : 4.14
--- DML_update_loss(A model) with Client:f2252_75: 2.85
--- DML_update_loss(A model) with Client:f3362_03: 3.41
--- DML_update_loss(A model) with Client:f1538_15: 3.67
--- DML_update_loss(A model) with Client:f3751_39: 3.90
--- DML_update_loss(A model) with Client:f1701_10: 2.94
--- DML_update_loss(A model) with Client:f2071_28: 2.80
--- DML_update_loss(A model) with Client:f4031_33: 3.37
--- DML_update_loss(A model) with Client:f0567_25: 3.34
--- DML_update_loss(A model) with Client:f0120_29: 3.38
--- DML_update_loss(A model) with Client:f0292_16: 3.54
--- DML_update_loss(A model) with Client:f0491_35: 3.45
--- DML_update_loss(A model) with Client:f3368_37: 3.89
--- DML_update_loss(A model) with Client:f3717_48: 3.45
--- DML_update_loss(A model) with Client:f0619_33: 3.69
--- DML_update_loss(A model) with Client:f0867_28: 3.73
--- DML_update_loss(A model) with Client:f3953_28: 2.86
--- DML_update_loss(A model) with Client:f1435_38: 3.38
--- DML_update_loss(A model) with Client:f1715_20: 3.05
--- DML_update_loss(A model) with Client:f3826_07: 3.84
--- DML_update_loss(A model) with Client:f3627_46: 3.53
----------- acc -----------
[2.272727272727273, 2.5, 0.0, 6.451612903225806, 0.0, 2.6315789473684212, 0.0, 0.0, 3.0303030303030303, 10.344827586206897, 0.0, 0.0, 0.0, 9.67741935483871, 4.444444444444445, 2.5, 0.0, 0.0, 2.272727272727273, 0.0, 0.0, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 0.0, 0.0, 0.0, 9.375, 0.0, 6.0606060606060606, 0.0, 5.0, 0.0, 2.7777777777777777, 0.0, 0.0, 2.4390243902439024, 0.0, 0.0, 3.225806451612903, 0.0, 5.2631578947368425, 0.0, 9.090909090909092, 2.7027027027027026, 0.0, 0.0, 4.0, 3.8461538461538463, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0, 0.0, 0.0, 6.25, 0.0, 0.0, 10.344827586206897, 0.0, 0.0, 0.0, 0.0, 0.0, 3.125, 3.0303030303030303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 6.25, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 0.0, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 5.555555555555555, 5.882352941176471, 0.0, 0.0, 18.181818181818183, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.14
--- All clients' test acc: 1.61%
2023-04-22 08:57:40,458 [MainThread] [INFO ]  Server train time: 47.702203035354614
2023-04-22 08:57:40,459 [MainThread] [INFO ]  
-------- round 1 --------
2023-04-22 08:57:40,459 [MainThread] [INFO ]  --- start training ---
client: f0312_43
--- local_update_loss : 4.12
client: f4031_33
--- local_update_loss : 2.57
client: f1431_47
--- local_update_loss : 4.12
client: f0781_31
--- local_update_loss : 4.13
client: f3776_05
--- local_update_loss : 4.10
client: f3817_22
--- local_update_loss : 4.13
client: f1929_04
--- local_update_loss : 4.12
client: f2589_78
--- local_update_loss : 4.12
client: f0676_08
--- local_update_loss : 4.11
client: f1129_22
--- local_update_loss : 4.12
client: f2322_80
--- local_update_loss : 4.14
client: f1157_43
--- local_update_loss : 4.11
client: f0132_17
--- local_update_loss : 4.11
client: f2455_72
--- local_update_loss : 4.15
client: f1675_40
--- local_update_loss : 4.11
client: f0567_25
--- local_update_loss : 3.10
client: f0928_42
--- local_update_loss : 4.14
client: f2517_63
--- local_update_loss : 4.11
client: f2178_93
--- local_update_loss : 4.14
client: f2170_68
--- local_update_loss : 4.15
--- DML_update_loss(A model) with Client:f0212_24: 3.48
--- DML_update_loss(A model) with Client:f0180_29: 3.32
--- DML_update_loss(A model) with Client:f0496_09: 3.60
--- DML_update_loss(A model) with Client:f1231_36: 3.69
--- DML_update_loss(A model) with Client:f1263_18: 3.67
--- DML_update_loss(A model) with Client:f0690_26: 3.62
--- DML_update_loss(A model) with Client:f0994_46: 3.40
--- DML_update_loss(A model) with Client:f1089_04: 3.75
--- DML_update_loss(A model) with Client:f0238_02: 3.51
--- DML_update_loss(A model) with Client:f3935_48: 3.59
--- DML_update_loss(A model) with Client:f0337_24: 3.48
--- DML_update_loss(A model) with Client:f0279_03: 3.36
--- DML_update_loss(A model) with Client:f3350_11: 3.62
--- DML_update_loss(A model) with Client:f3804_08: 3.56
--- DML_update_loss(A model) with Client:f2238_86: 3.34
--- DML_update_loss(A model) with Client:f3251_33: 3.79
--- DML_update_loss(A model) with Client:f1792_12: 3.50
--- DML_update_loss(A model) with Client:f3566_36: 3.43
--- DML_update_loss(A model) with Client:f4033_05: 3.62
--- DML_update_loss(A model) with Client:f2277_92: 3.64
----------- acc -----------
[2.272727272727273, 2.5, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 0.0, 0.0, 3.0303030303030303, 3.4482758620689653, 0.0, 0.0, 7.894736842105263, 9.67741935483871, 4.444444444444445, 2.5, 0.0, 0.0, 4.545454545454546, 0.0, 0.0, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 2.7777777777777777, 0.0, 0.0, 9.375, 0.0, 6.0606060606060606, 0.0, 5.0, 0.0, 2.7777777777777777, 9.75609756097561, 0.0, 2.4390243902439024, 0.0, 0.0, 3.225806451612903, 0.0, 5.2631578947368425, 0.0, 9.090909090909092, 2.7027027027027026, 0.0, 0.0, 4.0, 7.6923076923076925, 0.0, 0.0, 8.0, 0.0, 0.0, 5.0, 0.0, 2.9411764705882355, 0.0, 0.0, 0.0, 10.344827586206897, 0.0, 0.0, 0.0, 0.0, 0.0, 3.125, 3.0303030303030303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 6.25, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 13.333333333333334, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 0.0, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 18.181818181818183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.14
--- All clients' test acc: 1.89%
2023-04-22 08:58:27,008 [MainThread] [INFO ]  Server train time: 46.54802584648132
2023-04-22 08:58:27,009 [MainThread] [INFO ]  
-------- round 2 --------
2023-04-22 08:58:27,009 [MainThread] [INFO ]  --- start training ---
client: f0966_44
--- local_update_loss : 4.13
client: f1649_03
--- local_update_loss : 4.13
client: f1089_04
--- local_update_loss : 3.56
client: f0279_03
--- local_update_loss : 3.12
client: f2277_92
--- local_update_loss : 2.91
client: f0448_39
--- local_update_loss : 4.11
client: f1392_44
--- local_update_loss : 4.11
client: f1737_09
--- local_update_loss : 4.17
client: f1170_00
--- local_update_loss : 4.15
client: f0186_14
--- local_update_loss : 4.13
client: f0676_08
--- local_update_loss : 4.08
client: f0491_35
--- local_update_loss : 3.22
client: f0523_42
--- local_update_loss : 4.11
client: f3566_36
--- local_update_loss : 2.91
client: f0120_29
--- local_update_loss : 3.17
client: f0803_40
--- local_update_loss : 4.12
client: f2396_91
--- local_update_loss : 4.09
client: f3541_02
--- local_update_loss : 4.14
client: f3297_22
--- local_update_loss : 4.13
client: f3935_48
--- local_update_loss : 3.22
--- DML_update_loss(A model) with Client:f2275_90: 3.08
--- DML_update_loss(A model) with Client:f2271_86: 3.85
--- DML_update_loss(A model) with Client:f2071_28: 2.67
--- DML_update_loss(A model) with Client:f1519_36: 3.55
--- DML_update_loss(A model) with Client:f3310_44: 3.59
--- DML_update_loss(A model) with Client:f3948_41: 3.87
--- DML_update_loss(A model) with Client:f2322_80: 3.15
--- DML_update_loss(A model) with Client:f1616_04: 3.61
--- DML_update_loss(A model) with Client:f1129_22: 3.66
--- DML_update_loss(A model) with Client:f2412_86: 3.85
--- DML_update_loss(A model) with Client:f1313_04: 3.26
--- DML_update_loss(A model) with Client:f3300_25: 2.92
--- DML_update_loss(A model) with Client:f0628_05: 3.35
--- DML_update_loss(A model) with Client:f3826_07: 3.78
--- DML_update_loss(A model) with Client:f1771_46: 3.42
--- DML_update_loss(A model) with Client:f1696_08: 3.91
--- DML_update_loss(A model) with Client:f0869_20: 3.87
--- DML_update_loss(A model) with Client:f1439_27: 3.63
--- DML_update_loss(A model) with Client:f2517_63: 3.50
--- DML_update_loss(A model) with Client:f2503_57: 3.08
----------- acc -----------
[2.272727272727273, 2.5, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 0.0, 0.0, 3.0303030303030303, 3.4482758620689653, 0.0, 0.0, 7.894736842105263, 9.67741935483871, 4.444444444444445, 2.5, 0.0, 0.0, 4.545454545454546, 0.0, 0.0, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 2.7777777777777777, 0.0, 0.0, 9.375, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 2.4390243902439024, 0.0, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 9.090909090909092, 2.7027027027027026, 0.0, 0.0, 4.0, 7.6923076923076925, 0.0, 0.0, 8.0, 3.3333333333333335, 0.0, 5.0, 0.0, 2.9411764705882355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.125, 3.0303030303030303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 7.6923076923076925, 0.0, 0.0, 11.11111111111111, 6.25, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 13.333333333333334, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 18.75, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 0.0, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 18.181818181818183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.13
--- All clients' test acc: 2.13%
2023-04-22 08:59:02,605 [MainThread] [INFO ]  Server train time: 35.59492063522339
2023-04-22 08:59:02,605 [MainThread] [INFO ]  
-------- round 3 --------
2023-04-22 08:59:02,605 [MainThread] [INFO ]  --- start training ---
client: f0491_35
--- local_update_loss : 3.21
client: f0120_29
--- local_update_loss : 3.16
client: f1538_15
--- local_update_loss : 3.16
client: f3826_07
--- local_update_loss : 3.47
client: f0928_42
--- local_update_loss : 4.13
client: f2263_79
--- local_update_loss : 4.12
client: f0186_14
--- local_update_loss : 4.08
client: f3369_37
--- local_update_loss : 4.14
client: f1677_01
--- local_update_loss : 4.16
client: f1392_44
--- local_update_loss : 4.10
client: f2071_28
--- local_update_loss : 2.35
client: f3458_26
--- local_update_loss : 4.12
client: f0745_35
--- local_update_loss : 4.11
client: f2561_89
--- local_update_loss : 4.13
client: f0132_17
--- local_update_loss : 4.07
client: f0898_29
--- local_update_loss : 4.10
client: f4000_40
--- local_update_loss : 4.10
client: f1618_39
--- local_update_loss : 4.13
client: f2405_90
--- local_update_loss : 4.15
client: f1776_35
--- local_update_loss : 4.14
--- DML_update_loss(A model) with Client:f1231_36: 3.64
--- DML_update_loss(A model) with Client:f1649_03: 3.94
--- DML_update_loss(A model) with Client:f0062_25: 3.54
--- DML_update_loss(A model) with Client:f1758_36: 3.39
--- DML_update_loss(A model) with Client:f2277_92: 3.55
--- DML_update_loss(A model) with Client:f2013_19: 3.86
--- DML_update_loss(A model) with Client:f0359_05: 3.36
--- DML_update_loss(A model) with Client:f3804_08: 2.85
--- DML_update_loss(A model) with Client:f1997_00: 2.89
--- DML_update_loss(A model) with Client:f1519_36: 3.47
--- DML_update_loss(A model) with Client:f3300_25: 2.72
--- DML_update_loss(A model) with Client:f0212_24: 3.45
--- DML_update_loss(A model) with Client:f1170_00: 3.38
--- DML_update_loss(A model) with Client:f3935_48: 3.51
--- DML_update_loss(A model) with Client:f1844_38: 2.98
--- DML_update_loss(A model) with Client:f0781_31: 3.62
--- DML_update_loss(A model) with Client:f1565_04: 3.46
--- DML_update_loss(A model) with Client:f1540_20: 3.92
--- DML_update_loss(A model) with Client:f1089_04: 3.71
--- DML_update_loss(A model) with Client:f3776_05: 3.56
----------- acc -----------
[2.272727272727273, 2.5, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 0.0, 0.0, 6.0606060606060606, 3.4482758620689653, 0.0, 0.0, 7.894736842105263, 9.67741935483871, 4.444444444444445, 2.5, 0.0, 0.0, 4.545454545454546, 0.0, 0.0, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 2.7777777777777777, 0.0, 0.0, 9.375, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 2.4390243902439024, 0.0, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 9.090909090909092, 2.7027027027027026, 0.0, 0.0, 4.0, 7.6923076923076925, 0.0, 0.0, 0.0, 3.3333333333333335, 0.0, 5.0, 13.157894736842104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.125, 3.0303030303030303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 7.6923076923076925, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.333333333333334, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 18.75, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 0.0, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 18.181818181818183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.15
--- All clients' test acc: 2.11%
2023-04-22 08:59:44,291 [MainThread] [INFO ]  Server train time: 41.6845908164978
2023-04-22 08:59:44,292 [MainThread] [INFO ]  
-------- round 4 --------
2023-04-22 08:59:44,292 [MainThread] [INFO ]  --- start training ---
client: f3310_44
--- local_update_loss : 3.26
client: f0885_39
--- local_update_loss : 4.12
client: f3300_25
--- local_update_loss : 2.36
client: f3891_31
--- local_update_loss : 4.13
client: f0628_05
--- local_update_loss : 3.12
client: f0277_33
--- local_update_loss : 4.13
client: f0062_25
--- local_update_loss : 3.34
client: f1677_01
--- local_update_loss : 4.13
client: f1616_04
--- local_update_loss : 2.77
client: f1997_00
--- local_update_loss : 2.35
client: f3948_41
--- local_update_loss : 3.65
client: f3315_23
--- local_update_loss : 4.11
client: f0619_33
--- local_update_loss : 3.35
client: f3566_36
--- local_update_loss : 2.80
client: f3841_01
--- local_update_loss : 4.17
client: f3935_48
--- local_update_loss : 3.22
client: f3701_44
--- local_update_loss : 4.10
client: f1679_05
--- local_update_loss : 4.11
client: f1737_09
--- local_update_loss : 4.15
client: f0928_42
--- local_update_loss : 4.11
--- DML_update_loss(A model) with Client:f0180_29: 3.33
--- DML_update_loss(A model) with Client:f2312_87: 2.90
--- DML_update_loss(A model) with Client:f0132_17: 3.57
--- DML_update_loss(A model) with Client:f0359_05: 3.33
--- DML_update_loss(A model) with Client:f1263_18: 3.62
--- DML_update_loss(A model) with Client:f3675_24: 3.55
--- DML_update_loss(A model) with Client:f0279_03: 3.26
--- DML_update_loss(A model) with Client:f3435_24: 3.52
--- DML_update_loss(A model) with Client:f2322_80: 2.83
--- DML_update_loss(A model) with Client:f3369_37: 3.85
--- DML_update_loss(A model) with Client:f1556_19: 3.54
--- DML_update_loss(A model) with Client:f3717_48: 3.36
--- DML_update_loss(A model) with Client:f3388_36: 2.86
--- DML_update_loss(A model) with Client:f2241_88: 3.90
--- DML_update_loss(A model) with Client:f3627_46: 3.45
--- DML_update_loss(A model) with Client:f2396_91: 2.97
--- DML_update_loss(A model) with Client:f2337_71: 3.41
--- DML_update_loss(A model) with Client:f0448_39: 3.61
--- DML_update_loss(A model) with Client:f1063_36: 3.64
--- DML_update_loss(A model) with Client:f0257_46: 3.43
----------- acc -----------
[2.272727272727273, 2.5, 0.0, 6.451612903225806, 0.0, 2.6315789473684212, 0.0, 0.0, 6.0606060606060606, 3.4482758620689653, 7.894736842105263, 0.0, 2.6315789473684212, 9.67741935483871, 4.444444444444445, 2.5, 0.0, 0.0, 4.545454545454546, 0.0, 2.4390243902439024, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 2.7777777777777777, 0.0, 0.0, 9.375, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 2.4390243902439024, 0.0, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 6.0606060606060606, 2.7027027027027026, 0.0, 0.0, 4.0, 7.6923076923076925, 0.0, 2.6315789473684212, 0.0, 3.3333333333333335, 0.0, 5.0, 13.157894736842104, 0.0, 6.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.125, 3.0303030303030303, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 7.6923076923076925, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.333333333333334, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 18.75, 5.882352941176471, 0.0, 12.5, 22.22222222222222, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 11.764705882352942, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 16.666666666666668, 0.0, 5.882352941176471, 0.0, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 10.526315789473685, 5.882352941176471, 0.0, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 18.181818181818183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.14
--- All clients' test acc: 2.57%
2023-04-22 09:00:28,426 [MainThread] [INFO ]  Server train time: 44.133939027786255
2023-04-22 09:00:28,427 [MainThread] [INFO ]  
-------- round 5 --------
2023-04-22 09:00:28,427 [MainThread] [INFO ]  --- start training ---
client: f0491_35
--- local_update_loss : 3.21
client: f0186_14
--- local_update_loss : 4.01
client: f3435_24
--- local_update_loss : 3.17
client: f2071_28
--- local_update_loss : 2.33
client: f2069_42
--- local_update_loss : 4.13
client: f2466_76
--- local_update_loss : 4.13
client: f1313_04
--- local_update_loss : 3.02
client: f0994_46
--- local_update_loss : 3.06
client: f3315_23
--- local_update_loss : 4.05
client: f0120_29
--- local_update_loss : 3.16
client: f3627_46
--- local_update_loss : 3.18
client: f3350_11
--- local_update_loss : 3.35
client: f0522_38
--- local_update_loss : 4.16
client: f0773_10
--- local_update_loss : 4.10
client: f1715_20
--- local_update_loss : 2.40
client: f1089_04
--- local_update_loss : 3.56
client: f2455_72
--- local_update_loss : 4.14
client: f0496_09
--- local_update_loss : 3.41
client: f0385_18
--- local_update_loss : 4.12
client: f0329_34
--- local_update_loss : 4.12
--- DML_update_loss(A model) with Client:f1675_40: 3.66
--- DML_update_loss(A model) with Client:f3953_28: 2.76
--- DML_update_loss(A model) with Client:f2412_86: 3.66
--- DML_update_loss(A model) with Client:f1491_42: 3.37
--- DML_update_loss(A model) with Client:f3458_26: 3.58
--- DML_update_loss(A model) with Client:f0966_44: 3.70
--- DML_update_loss(A model) with Client:f2232_76: 3.47
--- DML_update_loss(A model) with Client:f0885_39: 3.48
--- DML_update_loss(A model) with Client:f3776_05: 3.47
--- DML_update_loss(A model) with Client:f1649_03: 3.87
--- DML_update_loss(A model) with Client:f3758_19: 4.01
--- DML_update_loss(A model) with Client:f3367_07: 3.51
--- DML_update_loss(A model) with Client:f1435_38: 3.34
--- DML_update_loss(A model) with Client:f3675_24: 3.46
--- DML_update_loss(A model) with Client:f1556_19: 3.44
--- DML_update_loss(A model) with Client:f1157_43: 3.45
--- DML_update_loss(A model) with Client:f0977_37: 3.34
--- DML_update_loss(A model) with Client:f3901_45: 3.48
--- DML_update_loss(A model) with Client:f1439_27: 3.59
--- DML_update_loss(A model) with Client:f3817_22: 3.40
----------- acc -----------
[2.272727272727273, 2.5, 0.0, 6.451612903225806, 0.0, 2.6315789473684212, 11.11111111111111, 0.0, 6.0606060606060606, 3.4482758620689653, 7.894736842105263, 0.0, 2.6315789473684212, 9.67741935483871, 4.444444444444445, 2.5, 0.0, 0.0, 4.545454545454546, 0.0, 2.4390243902439024, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 2.7777777777777777, 0.0, 0.0, 9.375, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 2.4390243902439024, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 2.7027027027027026, 0.0, 0.0, 20.0, 7.6923076923076925, 0.0, 2.6315789473684212, 0.0, 3.3333333333333335, 0.0, 5.0, 13.157894736842104, 0.0, 6.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.125, 3.0303030303030303, 6.451612903225806, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.090909090909092, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 7.6923076923076925, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.333333333333334, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 18.75, 5.882352941176471, 0.0, 12.5, 22.22222222222222, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 11.764705882352942, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 5.555555555555555, 16.666666666666668, 0.0, 5.882352941176471, 0.0, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 10.526315789473685, 5.882352941176471, 11.11111111111111, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 10.0, 0.0, 5.882352941176471, 0.0, 0.0, 18.181818181818183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.16
--- All clients' test acc: 2.97%
2023-04-22 09:01:05,734 [MainThread] [INFO ]  Server train time: 37.30533576011658
2023-04-22 09:01:05,736 [MainThread] [INFO ]  
-------- round 6 --------
2023-04-22 09:01:05,736 [MainThread] [INFO ]  --- start training ---
client: f0350_03
--- local_update_loss : 4.12
client: f3315_23
--- local_update_loss : 3.96
client: f1776_35
--- local_update_loss : 4.11
client: f3675_24
--- local_update_loss : 3.20
client: f1695_12
--- local_update_loss : 4.12
client: f1263_18
--- local_update_loss : 3.46
client: f0277_33
--- local_update_loss : 4.12
client: f0132_17
--- local_update_loss : 2.63
client: f1089_04
--- local_update_loss : 3.55
client: f0288_48
--- local_update_loss : 4.13
client: f1737_09
--- local_update_loss : 4.13
client: f1679_05
--- local_update_loss : 4.11
client: f0279_03
--- local_update_loss : 3.10
client: f1929_04
--- local_update_loss : 4.10
client: f1392_44
--- local_update_loss : 4.09
client: f4092_24
--- local_update_loss : 4.13
client: f3388_36
--- local_update_loss : 2.37
client: f2252_75
--- local_update_loss : 2.35
client: f0977_37
--- local_update_loss : 3.00
client: f1758_36
--- local_update_loss : 3.06
--- DML_update_loss(A model) with Client:f3826_07: 3.78
--- DML_update_loss(A model) with Client:f0994_46: 3.36
--- DML_update_loss(A model) with Client:f0496_09: 3.53
--- DML_update_loss(A model) with Client:f0745_35: 3.36
--- DML_update_loss(A model) with Client:f3367_07: 3.44
--- DML_update_loss(A model) with Client:f0522_38: 3.55
--- DML_update_loss(A model) with Client:f3581_23: 3.45
--- DML_update_loss(A model) with Client:f1435_38: 3.34
--- DML_update_loss(A model) with Client:f4040_28: 2.96
--- DML_update_loss(A model) with Client:f1439_27: 3.59
--- DML_update_loss(A model) with Client:f3490_39: 3.72
--- DML_update_loss(A model) with Client:f3717_48: 3.35
--- DML_update_loss(A model) with Client:f1129_22: 3.62
--- DML_update_loss(A model) with Client:f3948_41: 3.84
--- DML_update_loss(A model) with Client:f2277_92: 3.54
--- DML_update_loss(A model) with Client:f1499_12: 3.10
--- DML_update_loss(A model) with Client:f2238_86: 3.23
--- DML_update_loss(A model) with Client:f0521_14: 3.32
--- DML_update_loss(A model) with Client:f1936_06: 3.93
--- DML_update_loss(A model) with Client:f0567_25: 3.29
----------- acc -----------
[2.272727272727273, 2.5, 0.0, 6.451612903225806, 0.0, 2.6315789473684212, 11.11111111111111, 0.0, 6.0606060606060606, 3.4482758620689653, 7.894736842105263, 0.0, 2.6315789473684212, 9.67741935483871, 4.444444444444445, 2.5, 0.0, 0.0, 4.545454545454546, 0.0, 2.4390243902439024, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 0.0, 2.5641025641025643, 2.7027027027027026, 9.375, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 2.4390243902439024, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 2.7027027027027026, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 3.3333333333333335, 0.0, 5.0, 13.157894736842104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 3.125, 3.0303030303030303, 6.451612903225806, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.090909090909092, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 7.6923076923076925, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 13.333333333333334, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 17.647058823529413, 0.0, 18.75, 5.882352941176471, 0.0, 12.5, 22.22222222222222, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 11.764705882352942, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 16.666666666666668, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 0.0, 10.526315789473685, 5.882352941176471, 5.555555555555555, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 10.0, 0.0, 5.882352941176471, 17.647058823529413, 0.0, 18.181818181818183, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.15
--- All clients' test acc: 3.20%
2023-04-22 09:01:50,787 [MainThread] [INFO ]  Server train time: 45.04995942115784
2023-04-22 09:01:50,788 [MainThread] [INFO ]  
-------- round 7 --------
2023-04-22 09:01:50,788 [MainThread] [INFO ]  --- start training ---
client: f2561_89
--- local_update_loss : 4.12
client: f3310_44
--- local_update_loss : 3.22
client: f1618_39
--- local_update_loss : 4.11
client: f2178_93
--- local_update_loss : 4.13
client: f3193_08
--- local_update_loss : 4.12
client: f0432_28
--- local_update_loss : 4.12
client: f1401_36
--- local_update_loss : 4.13
client: f0474_10
--- local_update_loss : 4.12
client: f4033_05
--- local_update_loss : 3.27
client: f1540_20
--- local_update_loss : 3.68
client: f0613_28
--- local_update_loss : 4.11
client: f3350_11
--- local_update_loss : 3.26
client: f1792_12
--- local_update_loss : 3.17
client: f2238_86
--- local_update_loss : 2.94
client: f2071_28
--- local_update_loss : 2.32
client: f2503_57
--- local_update_loss : 2.34
client: f3388_36
--- local_update_loss : 2.36
client: f2506_77
--- local_update_loss : 4.13
client: f2412_86
--- local_update_loss : 2.80
client: f3366_32
--- local_update_loss : 4.08
--- DML_update_loss(A model) with Client:f1675_40: 3.55
--- DML_update_loss(A model) with Client:f2232_76: 3.38
--- DML_update_loss(A model) with Client:f3795_00: 2.97
--- DML_update_loss(A model) with Client:f1737_09: 3.01
--- DML_update_loss(A model) with Client:f3369_37: 3.79
--- DML_update_loss(A model) with Client:f0288_48: 3.36
--- DML_update_loss(A model) with Client:f3675_24: 3.47
--- DML_update_loss(A model) with Client:f1439_27: 3.58
--- DML_update_loss(A model) with Client:f1679_05: 3.88
--- DML_update_loss(A model) with Client:f3701_44: 2.91
--- DML_update_loss(A model) with Client:f2396_91: 2.70
--- DML_update_loss(A model) with Client:f0521_14: 3.29
--- DML_update_loss(A model) with Client:f1701_10: 2.70
--- DML_update_loss(A model) with Client:f2263_79: 3.56
--- DML_update_loss(A model) with Client:f1997_00: 2.69
--- DML_update_loss(A model) with Client:f3618_26: 3.55
--- DML_update_loss(A model) with Client:f0180_29: 3.33
--- DML_update_loss(A model) with Client:f2170_68: 3.62
--- DML_update_loss(A model) with Client:f0238_02: 3.46
--- DML_update_loss(A model) with Client:f1063_36: 3.59
----------- acc -----------
[2.272727272727273, 2.5, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 0.0, 6.0606060606060606, 0.0, 7.894736842105263, 0.0, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 0.0, 0.0, 4.545454545454546, 0.0, 2.4390243902439024, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 0.0, 0.0, 2.7027027027027026, 9.375, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 2.4390243902439024, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 2.7027027027027026, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 3.3333333333333335, 0.0, 5.0, 13.157894736842104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 3.125, 3.0303030303030303, 6.451612903225806, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 7.6923076923076925, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 17.647058823529413, 0.0, 18.75, 5.882352941176471, 0.0, 12.5, 22.22222222222222, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 10.526315789473685, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 11.764705882352942, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 5.555555555555555, 5.555555555555555, 16.666666666666668, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 5.555555555555555, 10.526315789473685, 5.882352941176471, 5.555555555555555, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 10.0, 0.0, 5.882352941176471, 17.647058823529413, 0.0, 18.181818181818183, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.16
--- All clients' test acc: 3.31%
2023-04-22 09:02:31,894 [MainThread] [INFO ]  Server train time: 41.10488820075989
2023-04-22 09:02:31,895 [MainThread] [INFO ]  
-------- round 8 --------
2023-04-22 09:02:31,895 [MainThread] [INFO ]  --- start training ---
client: f3817_22
--- local_update_loss : 3.04
client: f3618_26
--- local_update_loss : 3.21
client: f3627_46
--- local_update_loss : 3.15
client: f2561_89
--- local_update_loss : 4.10
client: f0062_25
--- local_update_loss : 3.34
client: f3826_07
--- local_update_loss : 3.48
client: f0491_35
--- local_update_loss : 3.21
client: f0496_09
--- local_update_loss : 3.40
client: f2076_31
--- local_update_loss : 4.11
client: f3675_24
--- local_update_loss : 3.21
client: f1776_35
--- local_update_loss : 4.09
client: f0448_39
--- local_update_loss : 3.46
client: f1737_09
--- local_update_loss : 2.54
client: f3891_31
--- local_update_loss : 4.12
client: f0994_46
--- local_update_loss : 2.99
client: f2517_63
--- local_update_loss : 3.17
client: f3751_39
--- local_update_loss : 3.67
client: f1869_07
--- local_update_loss : 4.13
client: f2589_78
--- local_update_loss : 4.10
client: f0120_29
--- local_update_loss : 3.16
--- DML_update_loss(A model) with Client:f1401_36: 3.25
--- DML_update_loss(A model) with Client:f0132_17: 3.36
--- DML_update_loss(A model) with Client:f1565_04: 3.40
--- DML_update_loss(A model) with Client:f1771_46: 3.20
--- DML_update_loss(A model) with Client:f3616_07: 2.88
--- DML_update_loss(A model) with Client:f1435_38: 3.34
--- DML_update_loss(A model) with Client:f1369_36: 3.51
--- DML_update_loss(A model) with Client:f0350_03: 3.42
--- DML_update_loss(A model) with Client:f3458_26: 3.55
--- DML_update_loss(A model) with Client:f3219_49: 3.69
--- DML_update_loss(A model) with Client:f2322_80: 2.74
--- DML_update_loss(A model) with Client:f3297_22: 2.91
--- DML_update_loss(A model) with Client:f1758_36: 3.33
--- DML_update_loss(A model) with Client:f4043_08: 3.41
--- DML_update_loss(A model) with Client:f3366_32: 3.80
--- DML_update_loss(A model) with Client:f1677_01: 2.92
--- DML_update_loss(A model) with Client:f1618_39: 3.55
--- DML_update_loss(A model) with Client:f2241_88: 3.85
--- DML_update_loss(A model) with Client:f1556_19: 3.41
--- DML_update_loss(A model) with Client:f3581_23: 3.09
----------- acc -----------
[2.272727272727273, 0.0, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 0.0, 6.0606060606060606, 0.0, 7.894736842105263, 0.0, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 0.0, 0.0, 4.545454545454546, 2.9411764705882355, 2.4390243902439024, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 0.0, 0.0, 2.7027027027027026, 9.375, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 2.4390243902439024, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 2.7027027027027026, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 3.3333333333333335, 0.0, 5.0, 13.157894736842104, 0.0, 0.0, 0.0, 0.0, 0.0, 9.30232558139535, 5.555555555555555, 0.0, 0.0, 5.555555555555555, 3.125, 3.0303030303030303, 6.451612903225806, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 17.647058823529413, 0.0, 18.75, 5.882352941176471, 0.0, 12.5, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 10.526315789473685, 0.0, 0.0, 0.0, 11.11111111111111, 11.11111111111111, 0.0, 11.764705882352942, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 5.555555555555555, 5.555555555555555, 16.666666666666668, 0.0, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 5.555555555555555, 10.526315789473685, 5.882352941176471, 11.11111111111111, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 5.555555555555555, 10.0, 0.0, 5.882352941176471, 17.647058823529413, 0.0, 18.181818181818183, 0.0, 0.0, 5.555555555555555, 12.5, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.17
--- All clients' test acc: 3.47%
2023-04-22 09:03:07,658 [MainThread] [INFO ]  Server train time: 35.7627158164978
2023-04-22 09:03:07,659 [MainThread] [INFO ]  
-------- round 9 --------
2023-04-22 09:03:07,660 [MainThread] [INFO ]  --- start training ---
client: f1538_15
--- local_update_loss : 3.14
client: f0359_05
--- local_update_loss : 3.19
client: f0521_14
--- local_update_loss : 3.08
client: f3368_37
--- local_update_loss : 3.39
client: f0547_28
--- local_update_loss : 4.15
client: f3938_46
--- local_update_loss : 4.11
client: f3776_05
--- local_update_loss : 3.24
client: f2455_72
--- local_update_loss : 4.13
client: f1089_04
--- local_update_loss : 3.54
client: f1618_39
--- local_update_loss : 2.92
client: f3541_02
--- local_update_loss : 4.13
client: f0773_10
--- local_update_loss : 4.08
client: f0329_34
--- local_update_loss : 4.10
client: f0928_42
--- local_update_loss : 4.10
client: f3953_28
--- local_update_loss : 2.42
client: f4064_46
--- local_update_loss : 4.11
client: f3105_03
--- local_update_loss : 4.10
client: f1136_31
--- local_update_loss : 4.10
client: f0288_48
--- local_update_loss : 3.14
client: f3616_07
--- local_update_loss : 2.36
--- DML_update_loss(A model) with Client:f1439_27: 3.59
--- DML_update_loss(A model) with Client:f0312_43: 3.40
--- DML_update_loss(A model) with Client:f1401_36: 3.17
--- DML_update_loss(A model) with Client:f3399_09: 3.04
--- DML_update_loss(A model) with Client:f0898_29: 3.51
--- DML_update_loss(A model) with Client:f0745_35: 3.33
--- DML_update_loss(A model) with Client:f3350_11: 3.72
--- DML_update_loss(A model) with Client:f3367_07: 3.44
--- DML_update_loss(A model) with Client:f3891_31: 3.82
--- DML_update_loss(A model) with Client:f0869_20: 3.60
--- DML_update_loss(A model) with Client:f1792_12: 3.40
--- DML_update_loss(A model) with Client:f1431_47: 3.66
--- DML_update_loss(A model) with Client:f1435_38: 3.34
--- DML_update_loss(A model) with Client:f2500_50: 3.86
--- DML_update_loss(A model) with Client:f1663_13: 3.59
--- DML_update_loss(A model) with Client:f2506_77: 3.77
--- DML_update_loss(A model) with Client:f1695_12: 3.64
--- DML_update_loss(A model) with Client:f1313_04: 3.20
--- DML_update_loss(A model) with Client:f3372_23: 3.95
--- DML_update_loss(A model) with Client:f0190_12: 3.63
----------- acc -----------
[2.272727272727273, 0.0, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 6.25, 6.0606060606060606, 0.0, 7.894736842105263, 0.0, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 4.761904761904762, 0.0, 4.545454545454546, 2.9411764705882355, 2.4390243902439024, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 0.0, 2.5641025641025643, 2.7027027027027026, 9.375, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 0.0, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 50.0, 3.0303030303030303, 8.108108108108109, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 3.3333333333333335, 0.0, 5.0, 13.157894736842104, 0.0, 0.0, 0.0, 0.0, 3.4482758620689653, 9.30232558139535, 5.555555555555555, 0.0, 20.0, 5.555555555555555, 3.125, 3.0303030303030303, 6.451612903225806, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 6.25, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 17.647058823529413, 0.0, 18.75, 5.882352941176471, 0.0, 12.5, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 0.0, 0.0, 0.0, 11.11111111111111, 11.11111111111111, 0.0, 11.764705882352942, 0.0, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 5.555555555555555, 10.526315789473685, 5.882352941176471, 11.11111111111111, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 10.0, 0.0, 5.882352941176471, 17.647058823529413, 0.0, 18.181818181818183, 0.0, 0.0, 5.555555555555555, 12.5, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.16
--- All clients' test acc: 4.02%
2023-04-22 09:03:51,551 [MainThread] [INFO ]  Server train time: 43.8905074596405
2023-04-22 09:03:51,553 [MainThread] [INFO ]  Model saved at /home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/main/femnist/saved_models/_global_model_r_9.pth
2023-04-22 09:03:51,554 [MainThread] [INFO ]  
-------- round 10 --------
2023-04-22 09:03:51,554 [MainThread] [INFO ]  --- start training ---
client: f1301_47
--- local_update_loss : 4.11
client: f2312_87
--- local_update_loss : 2.38
client: f0180_29
--- local_update_loss : 3.07
client: f2071_28
--- local_update_loss : 2.32
client: f1519_36
--- local_update_loss : 3.22
client: f1369_36
--- local_update_loss : 3.34
client: f0257_46
--- local_update_loss : 3.23
client: f2238_86
--- local_update_loss : 2.93
client: f0063_38
--- local_update_loss : 4.14
client: f1136_31
--- local_update_loss : 4.09
client: f2412_86
--- local_update_loss : 2.73
client: f3826_07
--- local_update_loss : 3.46
client: f0898_29
--- local_update_loss : 3.28
client: f1556_19
--- local_update_loss : 2.16
client: f1715_20
--- local_update_loss : 2.38
client: f0350_03
--- local_update_loss : 3.20
client: f1771_46
--- local_update_loss : 2.88
client: f2517_63
--- local_update_loss : 3.15
client: f0359_05
--- local_update_loss : 3.18
client: f2564_59
--- local_update_loss : 4.11
--- DML_update_loss(A model) with Client:f3581_23: 3.14
--- DML_update_loss(A model) with Client:f3616_07: 2.71
--- DML_update_loss(A model) with Client:f0523_42: 3.60
--- DML_update_loss(A model) with Client:f1129_22: 3.63
--- DML_update_loss(A model) with Client:f0521_14: 3.30
--- DML_update_loss(A model) with Client:f1263_18: 3.62
--- DML_update_loss(A model) with Client:f1291_26: 3.58
--- DML_update_loss(A model) with Client:f4000_40: 3.41
--- DML_update_loss(A model) with Client:f2241_88: 3.84
--- DML_update_loss(A model) with Client:f1538_15: 3.50
--- DML_update_loss(A model) with Client:f0803_40: 3.60
--- DML_update_loss(A model) with Client:f1649_03: 3.87
--- DML_update_loss(A model) with Client:f0522_38: 3.48
--- DML_update_loss(A model) with Client:f0885_39: 3.45
--- DML_update_loss(A model) with Client:f0781_31: 3.58
--- DML_update_loss(A model) with Client:f4043_08: 3.01
--- DML_update_loss(A model) with Client:f0995_43: 3.65
--- DML_update_loss(A model) with Client:f1696_08: 3.83
--- DML_update_loss(A model) with Client:f3948_41: 3.85
--- DML_update_loss(A model) with Client:f3350_11: 3.73
----------- acc -----------
[2.272727272727273, 0.0, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 6.25, 6.0606060606060606, 0.0, 7.894736842105263, 0.0, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 4.761904761904762, 0.0, 4.545454545454546, 2.9411764705882355, 0.0, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 0.0, 7.6923076923076925, 0.0, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 0.0, 3.3333333333333335, 0.0, 0.0, 0.0, 5.2631578947368425, 50.0, 6.0606060606060606, 8.108108108108109, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 3.3333333333333335, 4.545454545454546, 5.0, 13.157894736842104, 0.0, 0.0, 3.8461538461538463, 0.0, 3.4482758620689653, 9.30232558139535, 5.555555555555555, 0.0, 20.0, 5.555555555555555, 3.125, 3.0303030303030303, 6.451612903225806, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 6.25, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 15.384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 17.647058823529413, 0.0, 18.75, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 0.0, 0.0, 0.0, 11.11111111111111, 11.11111111111111, 0.0, 11.764705882352942, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 10.526315789473685, 5.882352941176471, 11.11111111111111, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 10.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.17
--- All clients' test acc: 3.77%
2023-04-22 09:04:36,725 [MainThread] [INFO ]  Server train time: 45.170140981674194
2023-04-22 09:04:36,725 [MainThread] [INFO ]  
-------- round 11 --------
2023-04-22 09:04:36,726 [MainThread] [INFO ]  --- start training ---
client: f0046_20
--- local_update_loss : 4.14
client: f2412_86
--- local_update_loss : 2.70
client: f2455_72
--- local_update_loss : 4.13
client: f2071_28
--- local_update_loss : 2.32
client: f1538_15
--- local_update_loss : 3.16
client: f1129_22
--- local_update_loss : 3.47
client: f0831_15
--- local_update_loss : 4.11
client: f4064_46
--- local_update_loss : 4.06
client: f4031_33
--- local_update_loss : 2.55
client: f3458_26
--- local_update_loss : 3.29
client: f0312_43
--- local_update_loss : 3.26
client: f1431_47
--- local_update_loss : 2.62
client: f0120_29
--- local_update_loss : 3.16
client: f1736_04
--- local_update_loss : 4.14
client: f3251_33
--- local_update_loss : 3.54
client: f1779_01
--- local_update_loss : 4.11
client: f0690_26
--- local_update_loss : 3.45
client: f2506_77
--- local_update_loss : 3.59
client: f1136_31
--- local_update_loss : 4.09
client: f0496_09
--- local_update_loss : 3.39
--- DML_update_loss(A model) with Client:f1792_12: 3.40
--- DML_update_loss(A model) with Client:f3315_23: 2.84
--- DML_update_loss(A model) with Client:f0337_24: 3.44
--- DML_update_loss(A model) with Client:f0869_20: 3.55
--- DML_update_loss(A model) with Client:f1435_38: 3.34
--- DML_update_loss(A model) with Client:f4092_24: 3.65
--- DML_update_loss(A model) with Client:f3529_11: 3.52
--- DML_update_loss(A model) with Client:f3675_24: 3.46
--- DML_update_loss(A model) with Client:f0773_10: 3.41
--- DML_update_loss(A model) with Client:f3219_49: 3.44
--- DML_update_loss(A model) with Client:f2271_86: 3.78
--- DML_update_loss(A model) with Client:f2589_78: 3.58
--- DML_update_loss(A model) with Client:f0885_39: 3.44
--- DML_update_loss(A model) with Client:f2561_89: 3.58
--- DML_update_loss(A model) with Client:f2241_88: 3.85
--- DML_update_loss(A model) with Client:f1480_24: 3.50
--- DML_update_loss(A model) with Client:f1291_26: 3.53
--- DML_update_loss(A model) with Client:f3369_37: 3.79
--- DML_update_loss(A model) with Client:f3189_40: 3.59
--- DML_update_loss(A model) with Client:f3350_11: 3.54
----------- acc -----------
[4.545454545454546, 0.0, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 6.25, 6.0606060606060606, 0.0, 7.894736842105263, 0.0, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 4.761904761904762, 0.0, 4.545454545454546, 2.9411764705882355, 0.0, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 0.0, 7.6923076923076925, 0.0, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 0.0, 3.3333333333333335, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 8.108108108108109, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 3.3333333333333335, 9.090909090909092, 5.0, 13.157894736842104, 0.0, 0.0, 3.8461538461538463, 0.0, 3.4482758620689653, 9.30232558139535, 5.555555555555555, 0.0, 0.0, 5.555555555555555, 3.125, 0.0, 6.451612903225806, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 6.25, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 15.384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 17.647058823529413, 0.0, 18.75, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 0.0, 0.0, 10.526315789473685, 0.0, 0.0, 11.764705882352942, 0.0, 10.526315789473685, 5.555555555555555, 0.0, 0.0, 11.11111111111111, 11.11111111111111, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 10.526315789473685, 5.882352941176471, 0.0, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 10.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.18
--- All clients' test acc: 3.34%
2023-04-22 09:05:19,330 [MainThread] [INFO ]  Server train time: 42.603254556655884
2023-04-22 09:05:19,330 [MainThread] [INFO ]  
-------- round 12 --------
2023-04-22 09:05:19,330 [MainThread] [INFO ]  --- start training ---
client: f0995_43
--- local_update_loss : 3.39
client: f0781_31
--- local_update_loss : 3.41
client: f2455_72
--- local_update_loss : 4.12
client: f3826_07
--- local_update_loss : 3.46
client: f1675_40
--- local_update_loss : 3.16
client: f3795_00
--- local_update_loss : 2.43
client: f1301_47
--- local_update_loss : 4.05
client: f0190_12
--- local_update_loss : 3.40
client: f1701_10
--- local_update_loss : 2.35
client: f0994_46
--- local_update_loss : 2.98
client: f1844_38
--- local_update_loss : 2.31
client: f2500_50
--- local_update_loss : 3.57
client: f0885_39
--- local_update_loss : 3.29
client: f0448_39
--- local_update_loss : 3.43
client: f0385_18
--- local_update_loss : 4.10
client: f1758_36
--- local_update_loss : 3.06
client: f3529_11
--- local_update_loss : 3.24
client: f3372_23
--- local_update_loss : 3.71
client: f3841_01
--- local_update_loss : 4.15
client: f0062_25
--- local_update_loss : 3.34
--- DML_update_loss(A model) with Client:f4040_28: 2.71
--- DML_update_loss(A model) with Client:f0977_37: 3.25
--- DML_update_loss(A model) with Client:f3297_22: 2.78
--- DML_update_loss(A model) with Client:f3948_41: 3.99
--- DML_update_loss(A model) with Client:f1313_04: 3.19
--- DML_update_loss(A model) with Client:f3368_37: 3.66
--- DML_update_loss(A model) with Client:f1519_36: 3.46
--- DML_update_loss(A model) with Client:f0337_24: 3.44
--- DML_update_loss(A model) with Client:f1649_03: 3.85
--- DML_update_loss(A model) with Client:f0212_24: 3.43
--- DML_update_loss(A model) with Client:f2271_86: 3.78
--- DML_update_loss(A model) with Client:f1736_04: 3.66
--- DML_update_loss(A model) with Client:f2466_76: 3.92
--- DML_update_loss(A model) with Client:f4031_33: 2.97
--- DML_update_loss(A model) with Client:f3804_08: 3.11
--- DML_update_loss(A model) with Client:f3189_40: 3.50
--- DML_update_loss(A model) with Client:f3193_08: 3.52
--- DML_update_loss(A model) with Client:f0869_20: 3.53
--- DML_update_loss(A model) with Client:f1715_20: 2.74
--- DML_update_loss(A model) with Client:f3581_23: 3.10
----------- acc -----------
[4.545454545454546, 0.0, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 6.25, 9.090909090909092, 0.0, 7.894736842105263, 0.0, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 4.761904761904762, 0.0, 11.363636363636363, 2.9411764705882355, 0.0, 2.5641025641025643, 3.125, 0.0, 0.0, 12.5, 0.0, 7.6923076923076925, 0.0, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 0.0, 3.3333333333333335, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 8.108108108108109, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 3.3333333333333335, 9.090909090909092, 5.0, 13.157894736842104, 0.0, 0.0, 3.8461538461538463, 0.0, 6.896551724137931, 9.30232558139535, 5.555555555555555, 0.0, 0.0, 5.555555555555555, 3.125, 0.0, 6.451612903225806, 7.142857142857143, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 6.25, 9.090909090909092, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 15.384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 17.647058823529413, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 10.526315789473685, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 5.555555555555555, 0.0, 0.0, 5.555555555555555, 11.11111111111111, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 10.526315789473685, 5.882352941176471, 0.0, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 10.0, 0.0, 5.882352941176471, 17.647058823529413, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.20
--- All clients' test acc: 3.64%
2023-04-22 09:05:57,164 [MainThread] [INFO ]  Server train time: 37.8332302570343
2023-04-22 09:05:57,165 [MainThread] [INFO ]  
-------- round 13 --------
2023-04-22 09:05:57,165 [MainThread] [INFO ]  --- start training ---
client: f2218_51
--- local_update_loss : 4.16
client: f2013_19
--- local_update_loss : 3.64
client: f1663_13
--- local_update_loss : 3.26
client: f2170_68
--- local_update_loss : 3.22
client: f1737_09
--- local_update_loss : 2.52
client: f3758_19
--- local_update_loss : 3.01
client: f1779_01
--- local_update_loss : 4.09
client: f2133_68
--- local_update_loss : 4.16
client: f0190_12
--- local_update_loss : 3.39
client: f1392_44
--- local_update_loss : 4.07
client: f2241_88
--- local_update_loss : 3.66
client: f1439_27
--- local_update_loss : 3.42
client: f0869_20
--- local_update_loss : 2.70
client: f0257_46
--- local_update_loss : 3.22
client: f4031_33
--- local_update_loss : 2.56
client: f0898_29
--- local_update_loss : 3.27
client: f3953_28
--- local_update_loss : 2.38
client: f0448_39
--- local_update_loss : 3.42
client: f0619_33
--- local_update_loss : 3.34
client: f0296_20
--- local_update_loss : 4.14
--- DML_update_loss(A model) with Client:f3618_26: 3.48
--- DML_update_loss(A model) with Client:f1089_04: 3.71
--- DML_update_loss(A model) with Client:f1556_19: 3.28
--- DML_update_loss(A model) with Client:f0277_33: 3.72
--- DML_update_loss(A model) with Client:f0885_39: 3.44
--- DML_update_loss(A model) with Client:f3935_48: 3.50
--- DML_update_loss(A model) with Client:f0773_10: 3.37
--- DML_update_loss(A model) with Client:f1435_38: 3.33
--- DML_update_loss(A model) with Client:f3948_41: 3.85
--- DML_update_loss(A model) with Client:f0312_43: 3.38
--- DML_update_loss(A model) with Client:f1491_42: 3.29
--- DML_update_loss(A model) with Client:f1565_04: 3.39
--- DML_update_loss(A model) with Client:f1696_08: 3.83
--- DML_update_loss(A model) with Client:f3372_23: 3.90
--- DML_update_loss(A model) with Client:f3105_03: 2.76
--- DML_update_loss(A model) with Client:f2412_86: 3.59
--- DML_update_loss(A model) with Client:f1936_06: 3.86
--- DML_update_loss(A model) with Client:f3297_22: 2.72
--- DML_update_loss(A model) with Client:f1157_43: 3.30
--- DML_update_loss(A model) with Client:f1869_07: 3.60
----------- acc -----------
[4.545454545454546, 0.0, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 3.125, 9.090909090909092, 0.0, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 11.363636363636363, 2.9411764705882355, 0.0, 2.5641025641025643, 3.125, 3.225806451612903, 0.0, 12.5, 0.0, 7.6923076923076925, 0.0, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 0.0, 3.3333333333333335, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 8.108108108108109, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 3.3333333333333335, 9.090909090909092, 0.0, 13.157894736842104, 0.0, 0.0, 3.8461538461538463, 0.0, 6.896551724137931, 9.30232558139535, 5.555555555555555, 0.0, 0.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 0.0, 9.090909090909092, 0.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 15.384615384615385, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 6.666666666666667, 5.2631578947368425, 0.0, 7.142857142857143, 0.0, 0.0, 17.647058823529413, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 5.555555555555555, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 10.526315789473685, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 5.555555555555555, 0.0, 0.0, 11.11111111111111, 11.11111111111111, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 5.555555555555555, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 5.882352941176471, 11.11111111111111, 10.526315789473685, 5.882352941176471, 0.0, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 10.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.19
--- All clients' test acc: 3.68%
2023-04-22 09:06:39,167 [MainThread] [INFO ]  Server train time: 42.00106930732727
2023-04-22 09:06:39,168 [MainThread] [INFO ]  
-------- round 14 --------
2023-04-22 09:06:39,168 [MainThread] [INFO ]  --- start training ---
client: f0186_14
--- local_update_loss : 3.88
client: f1491_42
--- local_update_loss : 3.09
client: f1089_04
--- local_update_loss : 3.55
client: f2312_87
--- local_update_loss : 2.34
client: f0474_10
--- local_update_loss : 4.11
client: f0180_29
--- local_update_loss : 3.05
client: f4064_46
--- local_update_loss : 3.98
client: f0296_20
--- local_update_loss : 4.13
client: f1715_20
--- local_update_loss : 2.39
client: f2277_92
--- local_update_loss : 2.48
client: f0312_43
--- local_update_loss : 3.26
client: f0928_42
--- local_update_loss : 4.08
client: f3616_07
--- local_update_loss : 2.34
client: f0869_20
--- local_update_loss : 2.19
client: f1129_22
--- local_update_loss : 3.46
client: f3297_22
--- local_update_loss : 2.40
client: f2564_59
--- local_update_loss : 4.11
client: f1779_01
--- local_update_loss : 4.07
client: f1936_06
--- local_update_loss : 3.62
client: f1231_36
--- local_update_loss : 3.51
--- DML_update_loss(A model) with Client:f1679_05: 3.82
--- DML_update_loss(A model) with Client:f1435_38: 3.34
--- DML_update_loss(A model) with Client:f2396_91: 2.75
--- DML_update_loss(A model) with Client:f0359_05: 3.33
--- DML_update_loss(A model) with Client:f0995_43: 3.57
--- DML_update_loss(A model) with Client:f2069_42: 3.66
--- DML_update_loss(A model) with Client:f0676_08: 3.57
--- DML_update_loss(A model) with Client:f1313_04: 3.20
--- DML_update_loss(A model) with Client:f3795_00: 2.83
--- DML_update_loss(A model) with Client:f1170_00: 3.33
--- DML_update_loss(A model) with Client:f2218_51: 3.00
--- DML_update_loss(A model) with Client:f4033_05: 3.52
--- DML_update_loss(A model) with Client:f1695_12: 3.53
--- DML_update_loss(A model) with Client:f0491_35: 3.39
--- DML_update_loss(A model) with Client:f1136_31: 3.56
--- DML_update_loss(A model) with Client:f3300_25: 2.79
--- DML_update_loss(A model) with Client:f3618_26: 3.47
--- DML_update_loss(A model) with Client:f3627_46: 3.41
--- DML_update_loss(A model) with Client:f0350_03: 3.38
--- DML_update_loss(A model) with Client:f0867_28: 3.71
----------- acc -----------
[4.545454545454546, 0.0, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 3.125, 9.090909090909092, 0.0, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 11.363636363636363, 0.0, 0.0, 2.5641025641025643, 3.125, 3.225806451612903, 0.0, 0.0, 0.0, 7.6923076923076925, 0.0, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 0.0, 3.3333333333333335, 0.0, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 8.108108108108109, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 3.3333333333333335, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 6.896551724137931, 9.30232558139535, 5.555555555555555, 0.0, 0.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 0.0, 9.090909090909092, 0.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 15.384615384615385, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 6.666666666666667, 5.2631578947368425, 13.333333333333334, 7.142857142857143, 0.0, 0.0, 17.647058823529413, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 10.526315789473685, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 5.555555555555555, 0.0, 0.0, 11.11111111111111, 5.555555555555555, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 5.555555555555555, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 0.0, 5.2631578947368425, 5.882352941176471, 0.0, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 10.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.19
--- All clients' test acc: 3.49%
2023-04-22 09:07:27,530 [MainThread] [INFO ]  Server train time: 48.36083364486694
2023-04-22 09:07:27,531 [MainThread] [INFO ]  
-------- round 15 --------
2023-04-22 09:07:27,531 [MainThread] [INFO ]  --- start training ---
client: f3795_00
--- local_update_loss : 2.38
client: f3519_18
--- local_update_loss : 4.11
client: f0928_42
--- local_update_loss : 4.05
client: f0690_26
--- local_update_loss : 3.44
client: f1540_20
--- local_update_loss : 3.67
client: f2466_76
--- local_update_loss : 3.72
client: f1439_27
--- local_update_loss : 3.41
client: f2412_86
--- local_update_loss : 3.15
client: f0279_03
--- local_update_loss : 3.09
client: f2500_50
--- local_update_loss : 3.56
client: f3310_44
--- local_update_loss : 3.21
client: f1401_36
--- local_update_loss : 2.98
client: f0496_09
--- local_update_loss : 3.39
client: f0238_02
--- local_update_loss : 3.32
client: f0385_18
--- local_update_loss : 4.07
client: f3297_22
--- local_update_loss : 2.39
client: f3435_24
--- local_update_loss : 3.15
client: f0781_31
--- local_update_loss : 3.41
client: f1701_10
--- local_update_loss : 2.31
client: f4040_28
--- local_update_loss : 2.42
--- DML_update_loss(A model) with Client:f2396_91: 2.73
--- DML_update_loss(A model) with Client:f3581_23: 3.09
--- DML_update_loss(A model) with Client:f3666_48: 3.52
--- DML_update_loss(A model) with Client:f1129_22: 3.63
--- DML_update_loss(A model) with Client:f0337_24: 3.44
--- DML_update_loss(A model) with Client:f0190_12: 3.56
--- DML_update_loss(A model) with Client:f3368_37: 3.80
--- DML_update_loss(A model) with Client:f3541_02: 3.60
--- DML_update_loss(A model) with Client:f0676_08: 3.55
--- DML_update_loss(A model) with Client:f3372_23: 3.90
--- DML_update_loss(A model) with Client:f1649_03: 3.84
--- DML_update_loss(A model) with Client:f1313_04: 3.20
--- DML_update_loss(A model) with Client:f1480_24: 3.45
--- DML_update_loss(A model) with Client:f0046_20: 3.30
--- DML_update_loss(A model) with Client:f3901_45: 3.31
--- DML_update_loss(A model) with Client:f0867_28: 3.70
--- DML_update_loss(A model) with Client:f3490_39: 3.66
--- DML_update_loss(A model) with Client:f2071_28: 2.65
--- DML_update_loss(A model) with Client:f3751_39: 3.82
--- DML_update_loss(A model) with Client:f2170_68: 3.53
----------- acc -----------
[2.272727272727273, 0.0, 0.0, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 3.125, 9.090909090909092, 3.4482758620689653, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 4.545454545454546, 0.0, 0.0, 2.5641025641025643, 3.125, 3.225806451612903, 0.0, 0.0, 2.7777777777777777, 7.6923076923076925, 0.0, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 0.0, 3.3333333333333335, 0.0, 0.0, 0.0, 2.6315789473684212, 0.0, 3.0303030303030303, 8.108108108108109, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 6.896551724137931, 9.30232558139535, 5.555555555555555, 12.0, 0.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 0.0, 9.090909090909092, 0.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 15.384615384615385, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 6.666666666666667, 5.2631578947368425, 13.333333333333334, 7.142857142857143, 0.0, 0.0, 17.647058823529413, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 10.526315789473685, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 5.555555555555555, 0.0, 0.0, 11.11111111111111, 5.555555555555555, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 11.11111111111111, 0.0, 5.882352941176471, 11.764705882352942, 0.0, 5.2631578947368425, 5.882352941176471, 0.0, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.20
--- All clients' test acc: 3.54%
2023-04-22 09:08:13,898 [MainThread] [INFO ]  Server train time: 46.36608076095581
2023-04-22 09:08:13,899 [MainThread] [INFO ]  
-------- round 16 --------
2023-04-22 09:08:13,899 [MainThread] [INFO ]  --- start training ---
client: f4033_05
--- local_update_loss : 3.27
client: f2271_86
--- local_update_loss : 3.55
client: f4092_24
--- local_update_loss : 3.27
client: f3490_39
--- local_update_loss : 3.41
client: f2589_78
--- local_update_loss : 3.17
client: f1715_20
--- local_update_loss : 2.37
client: f3366_32
--- local_update_loss : 2.63
client: f0966_44
--- local_update_loss : 3.53
client: f0885_39
--- local_update_loss : 3.30
client: f1063_36
--- local_update_loss : 3.47
client: f2170_68
--- local_update_loss : 3.22
client: f0046_20
--- local_update_loss : 3.12
client: f2133_68
--- local_update_loss : 4.15
client: f2506_77
--- local_update_loss : 3.51
client: f2013_19
--- local_update_loss : 3.63
client: f1499_12
--- local_update_loss : 2.51
client: f1301_47
--- local_update_loss : 3.98
client: f0190_12
--- local_update_loss : 3.40
client: f0613_28
--- local_update_loss : 4.10
client: f3566_36
--- local_update_loss : 2.78
--- DML_update_loss(A model) with Client:f2071_28: 2.66
--- DML_update_loss(A model) with Client:f1401_36: 3.17
--- DML_update_loss(A model) with Client:f0312_43: 3.38
--- DML_update_loss(A model) with Client:f2263_79: 3.54
--- DML_update_loss(A model) with Client:f3399_09: 2.75
--- DML_update_loss(A model) with Client:f1431_47: 3.07
--- DML_update_loss(A model) with Client:f0132_17: 3.35
--- DML_update_loss(A model) with Client:f2218_51: 2.79
--- DML_update_loss(A model) with Client:f3953_28: 2.72
--- DML_update_loss(A model) with Client:f2232_76: 3.39
--- DML_update_loss(A model) with Client:f2396_91: 2.71
--- DML_update_loss(A model) with Client:f0212_24: 3.44
--- DML_update_loss(A model) with Client:f0491_35: 3.39
--- DML_update_loss(A model) with Client:f0350_03: 3.41
--- DML_update_loss(A model) with Client:f2322_80: 2.75
--- DML_update_loss(A model) with Client:f3300_25: 2.76
--- DML_update_loss(A model) with Client:f3529_11: 3.51
--- DML_update_loss(A model) with Client:f1929_04: 3.06
--- DML_update_loss(A model) with Client:f0994_46: 3.29
--- DML_update_loss(A model) with Client:f0063_38: 3.39
----------- acc -----------
[2.272727272727273, 0.0, 14.285714285714286, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 6.25, 3.0303030303030303, 3.4482758620689653, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 0.0, 0.0, 4.545454545454546, 0.0, 0.0, 2.5641025641025643, 3.125, 3.225806451612903, 0.0, 0.0, 2.7777777777777777, 7.6923076923076925, 0.0, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 0.0, 3.3333333333333335, 0.0, 0.0, 0.0, 2.6315789473684212, 0.0, 3.0303030303030303, 8.108108108108109, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 6.896551724137931, 9.30232558139535, 5.555555555555555, 0.0, 20.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 0.0, 9.090909090909092, 0.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 15.384615384615385, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 16.666666666666668, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 6.666666666666667, 5.2631578947368425, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 10.526315789473685, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 5.555555555555555, 0.0, 0.0, 11.11111111111111, 5.555555555555555, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 33.333333333333336, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 11.11111111111111, 0.0, 5.882352941176471, 11.764705882352942, 0.0, 5.2631578947368425, 5.882352941176471, 0.0, 5.555555555555555, 5.555555555555555, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.19
--- All clients' test acc: 3.79%
2023-04-22 09:08:53,645 [MainThread] [INFO ]  Server train time: 39.74523687362671
2023-04-22 09:08:53,646 [MainThread] [INFO ]  
-------- round 17 --------
2023-04-22 09:08:53,646 [MainThread] [INFO ]  --- start training ---
client: f1649_03
--- local_update_loss : 3.74
client: f1556_19
--- local_update_loss : 2.12
client: f3701_44
--- local_update_loss : 2.42
client: f0312_43
--- local_update_loss : 3.25
client: f3953_28
--- local_update_loss : 2.39
client: f2071_28
--- local_update_loss : 2.33
client: f2503_57
--- local_update_loss : 2.32
client: f2013_19
--- local_update_loss : 3.63
client: f1480_24
--- local_update_loss : 3.27
client: f0733_34
--- local_update_loss : 4.11
client: f3399_09
--- local_update_loss : 2.35
client: f1538_15
--- local_update_loss : 3.12
client: f3717_48
--- local_update_loss : 3.07
client: f0046_20
--- local_update_loss : 3.09
client: f2277_92
--- local_update_loss : 2.39
client: f2238_86
--- local_update_loss : 2.92
client: f1936_06
--- local_update_loss : 3.62
client: f0277_33
--- local_update_loss : 3.53
client: f3369_37
--- local_update_loss : 3.57
client: f2589_78
--- local_update_loss : 3.16
--- DML_update_loss(A model) with Client:f1565_04: 3.39
--- DML_update_loss(A model) with Client:f3566_36: 3.51
--- DML_update_loss(A model) with Client:f2178_93: 3.85
--- DML_update_loss(A model) with Client:f0869_20: 3.60
--- DML_update_loss(A model) with Client:f3817_22: 3.31
--- DML_update_loss(A model) with Client:f1519_36: 3.48
--- DML_update_loss(A model) with Client:f3368_37: 3.67
--- DML_update_loss(A model) with Client:f1679_05: 3.82
--- DML_update_loss(A model) with Client:f0132_17: 3.39
--- DML_update_loss(A model) with Client:f1736_04: 3.57
--- DML_update_loss(A model) with Client:f2312_87: 2.75
--- DML_update_loss(A model) with Client:f3795_00: 2.70
--- DML_update_loss(A model) with Client:f1663_13: 3.50
--- DML_update_loss(A model) with Client:f2466_76: 3.87
--- DML_update_loss(A model) with Client:f1616_04: 3.44
--- DML_update_loss(A model) with Client:f0898_29: 3.46
--- DML_update_loss(A model) with Client:f0448_39: 3.58
--- DML_update_loss(A model) with Client:f1715_20: 2.73
--- DML_update_loss(A model) with Client:f2263_79: 3.59
--- DML_update_loss(A model) with Client:f3366_32: 4.16
----------- acc -----------
[2.272727272727273, 0.0, 14.285714285714286, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 6.25, 3.0303030303030303, 3.4482758620689653, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 4.545454545454546, 0.0, 0.0, 2.5641025641025643, 3.125, 0.0, 0.0, 0.0, 2.7777777777777777, 7.6923076923076925, 0.0, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 0.0, 0.0, 3.3333333333333335, 0.0, 0.0, 0.0, 2.6315789473684212, 0.0, 3.0303030303030303, 5.405405405405405, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 6.896551724137931, 9.30232558139535, 5.555555555555555, 0.0, 20.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 12.5, 0.0, 12.5, 9.090909090909092, 0.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 15.384615384615385, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 16.666666666666668, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 6.666666666666667, 0.0, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 10.526315789473685, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 5.555555555555555, 0.0, 0.0, 11.11111111111111, 5.555555555555555, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 11.11111111111111, 0.0, 5.882352941176471, 11.764705882352942, 0.0, 5.2631578947368425, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.19
--- All clients' test acc: 3.56%
2023-04-22 09:09:25,919 [MainThread] [INFO ]  Server train time: 32.27178883552551
2023-04-22 09:09:25,919 [MainThread] [INFO ]  
-------- round 18 --------
2023-04-22 09:09:25,919 [MainThread] [INFO ]  --- start training ---
client: f2503_57
--- local_update_loss : 2.32
client: f3315_23
--- local_update_loss : 2.36
client: f0619_33
--- local_update_loss : 3.34
client: f0474_10
--- local_update_loss : 4.10
client: f2238_86
--- local_update_loss : 2.92
client: f1369_36
--- local_update_loss : 3.33
client: f0132_17
--- local_update_loss : 2.63
client: f0337_24
--- local_update_loss : 3.30
client: f0046_20
--- local_update_loss : 3.08
client: f3362_03
--- local_update_loss : 3.08
client: f2322_80
--- local_update_loss : 2.41
client: f0773_10
--- local_update_loss : 3.16
client: f0279_03
--- local_update_loss : 3.09
client: f2232_76
--- local_update_loss : 3.02
client: f2466_76
--- local_update_loss : 3.71
client: f1771_46
--- local_update_loss : 2.80
client: f0966_44
--- local_update_loss : 3.50
client: f0781_31
--- local_update_loss : 3.41
client: f1136_31
--- local_update_loss : 3.29
client: f0329_34
--- local_update_loss : 4.08
--- DML_update_loss(A model) with Client:f3795_00: 2.72
--- DML_update_loss(A model) with Client:f1618_39: 3.66
--- DML_update_loss(A model) with Client:f3297_22: 2.74
--- DML_update_loss(A model) with Client:f3953_28: 2.74
--- DML_update_loss(A model) with Client:f3938_46: 3.46
--- DML_update_loss(A model) with Client:f2170_68: 3.52
--- DML_update_loss(A model) with Client:f0063_38: 2.89
--- DML_update_loss(A model) with Client:f3948_41: 3.83
--- DML_update_loss(A model) with Client:f0523_42: 3.55
--- DML_update_loss(A model) with Client:f1679_05: 3.82
--- DML_update_loss(A model) with Client:f3399_09: 2.65
--- DML_update_loss(A model) with Client:f3367_07: 3.44
--- DML_update_loss(A model) with Client:f0733_34: 3.43
--- DML_update_loss(A model) with Client:f2252_75: 2.68
--- DML_update_loss(A model) with Client:f4092_24: 3.57
--- DML_update_loss(A model) with Client:f2561_89: 3.54
--- DML_update_loss(A model) with Client:f2405_90: 3.55
--- DML_update_loss(A model) with Client:f1313_04: 3.19
--- DML_update_loss(A model) with Client:f1779_01: 3.49
--- DML_update_loss(A model) with Client:f1263_18: 3.61
----------- acc -----------
[2.272727272727273, 0.0, 14.285714285714286, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 6.25, 3.0303030303030303, 3.4482758620689653, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 4.545454545454546, 0.0, 0.0, 2.5641025641025643, 3.125, 0.0, 0.0, 0.0, 2.7777777777777777, 7.6923076923076925, 0.0, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 2.7027027027027026, 0.0, 3.3333333333333335, 0.0, 0.0, 0.0, 2.6315789473684212, 0.0, 3.0303030303030303, 5.405405405405405, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 10.344827586206897, 9.30232558139535, 5.555555555555555, 0.0, 20.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 12.5, 0.0, 12.5, 9.090909090909092, 0.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 15.384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0, 16.666666666666668, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 5.2631578947368425, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 5.555555555555555, 0.0, 0.0, 11.11111111111111, 5.555555555555555, 0.0, 11.764705882352942, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 11.11111111111111, 0.0, 5.882352941176471, 11.764705882352942, 0.0, 5.2631578947368425, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 11.11111111111111, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 13.333333333333334]
--------- test avarage ---------
--- All clients' test loss: 4.20
--- All clients' test acc: 3.60%
2023-04-22 09:10:04,291 [MainThread] [INFO ]  Server train time: 38.371098279953
2023-04-22 09:10:04,292 [MainThread] [INFO ]  
-------- round 19 --------
2023-04-22 09:10:04,292 [MainThread] [INFO ]  --- start training ---
client: f3367_07
--- local_update_loss : 3.20
client: f3105_03
--- local_update_loss : 2.37
client: f3369_37
--- local_update_loss : 3.56
client: f3372_23
--- local_update_loss : 3.70
client: f2238_86
--- local_update_loss : 2.92
client: f1301_47
--- local_update_loss : 3.85
client: f1291_26
--- local_update_loss : 3.34
client: f1263_18
--- local_update_loss : 3.46
client: f0312_43
--- local_update_loss : 3.25
client: f2503_57
--- local_update_loss : 2.32
client: f4040_28
--- local_update_loss : 2.40
client: f3519_18
--- local_update_loss : 4.09
client: f3826_07
--- local_update_loss : 3.46
client: f0567_25
--- local_update_loss : 3.10
client: f0619_33
--- local_update_loss : 3.33
client: f0547_28
--- local_update_loss : 4.14
client: f0733_34
--- local_update_loss : 3.20
client: f2396_91
--- local_update_loss : 2.40
client: f0062_25
--- local_update_loss : 3.33
client: f4064_46
--- local_update_loss : 3.84
--- DML_update_loss(A model) with Client:f1392_44: 3.31
--- DML_update_loss(A model) with Client:f0867_28: 3.70
--- DML_update_loss(A model) with Client:f0432_28: 3.70
--- DML_update_loss(A model) with Client:f0522_38: 3.49
--- DML_update_loss(A model) with Client:f4033_05: 3.52
--- DML_update_loss(A model) with Client:f1556_19: 3.28
--- DML_update_loss(A model) with Client:f3935_48: 3.51
--- DML_update_loss(A model) with Client:f3490_39: 3.67
--- DML_update_loss(A model) with Client:f2076_31: 3.64
--- DML_update_loss(A model) with Client:f0474_10: 3.46
--- DML_update_loss(A model) with Client:f1431_47: 3.10
--- DML_update_loss(A model) with Client:f3841_01: 2.88
--- DML_update_loss(A model) with Client:f3776_05: 3.48
--- DML_update_loss(A model) with Client:f3251_33: 3.74
--- DML_update_loss(A model) with Client:f3541_02: 3.53
--- DML_update_loss(A model) with Client:f0277_33: 3.69
--- DML_update_loss(A model) with Client:f3627_46: 3.42
--- DML_update_loss(A model) with Client:f4043_08: 2.98
--- DML_update_loss(A model) with Client:f2412_86: 3.54
--- DML_update_loss(A model) with Client:f0781_31: 3.57
----------- acc -----------
[2.272727272727273, 0.0, 14.285714285714286, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 6.25, 3.0303030303030303, 3.4482758620689653, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 4.545454545454546, 0.0, 0.0, 2.5641025641025643, 3.125, 0.0, 8.333333333333334, 0.0, 2.7777777777777777, 7.6923076923076925, 8.108108108108109, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 2.7027027027027026, 0.0, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 5.405405405405405, 0.0, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 10.344827586206897, 9.30232558139535, 2.7777777777777777, 0.0, 20.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 12.5, 0.0, 12.5, 9.090909090909092, 0.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 15.384615384615385, 0.0, 0.0, 0.0, 0.0, 0.0, 16.666666666666668, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 33.333333333333336, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 5.2631578947368425, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 5.555555555555555, 0.0, 0.0, 11.11111111111111, 5.555555555555555, 0.0, 11.764705882352942, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 0.0, 5.2631578947368425, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 5.555555555555555, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 5.555555555555555, 25.0, 0.0, 13.333333333333334]
--------- test avarage ---------
--- All clients' test loss: 4.20
--- All clients' test acc: 3.96%
2023-04-22 09:10:43,907 [MainThread] [INFO ]  Server train time: 39.61417317390442
2023-04-22 09:10:43,910 [MainThread] [INFO ]  Model saved at /home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/main/femnist/saved_models/_global_model_r_19.pth
2023-04-22 09:10:43,910 [MainThread] [INFO ]  
-------- round 20 --------
2023-04-22 09:10:43,910 [MainThread] [INFO ]  --- start training ---
client: f2517_63
--- local_update_loss : 3.14
client: f0928_42
--- local_update_loss : 4.01
client: f1736_04
--- local_update_loss : 3.28
client: f3189_40
--- local_update_loss : 3.21
client: f3953_28
--- local_update_loss : 2.39
client: f1701_10
--- local_update_loss : 2.31
client: f1392_44
--- local_update_loss : 3.12
client: f2076_31
--- local_update_loss : 3.84
client: f2396_91
--- local_update_loss : 2.39
client: f0628_05
--- local_update_loss : 3.10
client: f0288_48
--- local_update_loss : 3.13
client: f3891_31
--- local_update_loss : 3.58
client: f1929_04
--- local_update_loss : 2.54
client: f2252_75
--- local_update_loss : 2.38
client: f0522_38
--- local_update_loss : 3.33
client: f3251_33
--- local_update_loss : 3.53
client: f3817_22
--- local_update_loss : 3.02
client: f4040_28
--- local_update_loss : 2.40
client: f1771_46
--- local_update_loss : 2.78
client: f3193_08
--- local_update_loss : 3.19
--- DML_update_loss(A model) with Client:f0773_10: 3.36
--- DML_update_loss(A model) with Client:f1435_38: 3.33
--- DML_update_loss(A model) with Client:f3490_39: 3.67
--- DML_update_loss(A model) with Client:f0180_29: 3.34
--- DML_update_loss(A model) with Client:f3372_23: 3.90
--- DML_update_loss(A model) with Client:f3841_01: 2.70
--- DML_update_loss(A model) with Client:f2232_76: 3.39
--- DML_update_loss(A model) with Client:f3618_26: 3.46
--- DML_update_loss(A model) with Client:f2238_86: 3.24
--- DML_update_loss(A model) with Client:f0745_35: 3.36
--- DML_update_loss(A model) with Client:f2133_68: 3.41
--- DML_update_loss(A model) with Client:f3290_01: 3.51
--- DML_update_loss(A model) with Client:f0676_08: 3.55
--- DML_update_loss(A model) with Client:f2241_88: 3.85
--- DML_update_loss(A model) with Client:f2466_76: 3.87
--- DML_update_loss(A model) with Client:f2263_79: 3.51
--- DML_update_loss(A model) with Client:f4064_46: 3.42
--- DML_update_loss(A model) with Client:f1618_39: 3.41
--- DML_update_loss(A model) with Client:f0257_46: 3.40
--- DML_update_loss(A model) with Client:f4092_24: 3.57
----------- acc -----------
[2.272727272727273, 0.0, 14.285714285714286, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 6.25, 3.0303030303030303, 3.4482758620689653, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 4.545454545454546, 0.0, 0.0, 2.5641025641025643, 3.125, 0.0, 8.333333333333334, 0.0, 2.7777777777777777, 7.6923076923076925, 2.7027027027027026, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 2.7027027027027026, 2.4390243902439024, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 5.405405405405405, 2.5641025641025643, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 10.344827586206897, 9.30232558139535, 5.555555555555555, 0.0, 20.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 12.5, 0.0, 12.5, 9.090909090909092, 0.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 7.6923076923076925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 33.333333333333336, 6.25, 0.0, 0.0, 0.0, 7.142857142857143, 5.882352941176471, 0.0, 17.647058823529413, 5.555555555555555, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 5.2631578947368425, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 10.526315789473685, 5.555555555555555, 0.0, 0.0, 11.11111111111111, 5.555555555555555, 0.0, 11.764705882352942, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 21.05263157894737, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 5.555555555555555, 5.2631578947368425, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 5.555555555555555, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 25.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.20
--- All clients' test acc: 3.97%
2023-04-22 09:11:26,355 [MainThread] [INFO ]  Server train time: 42.44443941116333
2023-04-22 09:11:26,356 [MainThread] [INFO ]  
-------- round 21 --------
2023-04-22 09:11:26,356 [MainThread] [INFO ]  --- start training ---
client: f0288_48
--- local_update_loss : 3.13
client: f0350_03
--- local_update_loss : 3.19
client: f3804_08
--- local_update_loss : 2.25
client: f3251_33
--- local_update_loss : 3.52
client: f1491_42
--- local_update_loss : 3.04
client: f0238_02
--- local_update_loss : 3.30
client: f3350_11
--- local_update_loss : 3.29
client: f2071_28
--- local_update_loss : 2.32
client: f1063_36
--- local_update_loss : 3.45
client: f0063_38
--- local_update_loss : 2.23
client: f2500_50
--- local_update_loss : 3.56
client: f3529_11
--- local_update_loss : 3.24
client: f1736_04
--- local_update_loss : 3.26
client: f0385_18
--- local_update_loss : 4.04
client: f2178_93
--- local_update_loss : 3.63
client: f3666_48
--- local_update_loss : 3.20
client: f2312_87
--- local_update_loss : 2.34
client: f0329_34
--- local_update_loss : 4.06
client: f0359_05
--- local_update_loss : 3.18
client: f0885_39
--- local_update_loss : 3.29
--- DML_update_loss(A model) with Client:f0619_33: 3.60
--- DML_update_loss(A model) with Client:f3817_22: 3.31
--- DML_update_loss(A model) with Client:f1089_04: 3.71
--- DML_update_loss(A model) with Client:f1435_38: 3.34
--- DML_update_loss(A model) with Client:f1401_36: 3.17
--- DML_update_loss(A model) with Client:f3627_46: 3.42
--- DML_update_loss(A model) with Client:f3219_49: 3.48
--- DML_update_loss(A model) with Client:f2322_80: 2.79
--- DML_update_loss(A model) with Client:f3458_26: 3.55
--- DML_update_loss(A model) with Client:f1869_07: 3.52
--- DML_update_loss(A model) with Client:f3193_08: 3.47
--- DML_update_loss(A model) with Client:f4000_40: 3.26
--- DML_update_loss(A model) with Client:f1715_20: 2.70
--- DML_update_loss(A model) with Client:f2013_19: 3.80
--- DML_update_loss(A model) with Client:f0690_26: 3.59
--- DML_update_loss(A model) with Client:f3290_01: 3.45
--- DML_update_loss(A model) with Client:f2263_79: 3.52
--- DML_update_loss(A model) with Client:f1565_04: 3.40
--- DML_update_loss(A model) with Client:f0496_09: 3.53
--- DML_update_loss(A model) with Client:f1231_36: 3.64
----------- acc -----------
[2.272727272727273, 0.0, 14.285714285714286, 6.451612903225806, 0.0, 7.894736842105263, 11.11111111111111, 6.25, 3.0303030303030303, 3.4482758620689653, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 4.545454545454546, 0.0, 0.0, 5.128205128205129, 3.125, 0.0, 8.333333333333334, 0.0, 0.0, 7.6923076923076925, 2.7027027027027026, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 2.7027027027027026, 2.4390243902439024, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 3.0303030303030303, 5.405405405405405, 2.5641025641025643, 0.0, 20.0, 3.8461538461538463, 0.0, 5.2631578947368425, 8.0, 10.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 10.344827586206897, 9.30232558139535, 5.555555555555555, 0.0, 20.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 12.5, 9.090909090909092, 0.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 7.6923076923076925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 0.0, 0.0, 33.333333333333336, 6.25, 0.0, 0.0, 0.0, 7.142857142857143, 5.882352941176471, 0.0, 17.647058823529413, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 5.2631578947368425, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 0.0, 16.666666666666668, 0.0, 5.2631578947368425, 11.11111111111111, 5.555555555555555, 0.0, 11.764705882352942, 5.882352941176471, 5.555555555555555, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 5.555555555555555, 5.2631578947368425, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 5.555555555555555, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 25.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.19
--- All clients' test acc: 3.84%
2023-04-22 09:12:08,745 [MainThread] [INFO ]  Server train time: 42.3878710269928
2023-04-22 09:12:08,745 [MainThread] [INFO ]  
-------- round 22 --------
2023-04-22 09:12:08,746 [MainThread] [INFO ]  --- start training ---
client: f1758_36
--- local_update_loss : 3.02
client: f1677_01
--- local_update_loss : 2.38
client: f1771_46
--- local_update_loss : 2.78
client: f0898_29
--- local_update_loss : 3.27
client: f0359_05
--- local_update_loss : 3.17
client: f2503_57
--- local_update_loss : 2.32
client: f0547_28
--- local_update_loss : 4.13
client: f2238_86
--- local_update_loss : 2.95
client: f2396_91
--- local_update_loss : 2.38
client: f1431_47
--- local_update_loss : 2.54
client: f2561_89
--- local_update_loss : 3.31
client: f0867_28
--- local_update_loss : 3.60
client: f1997_00
--- local_update_loss : 2.35
client: f3519_18
--- local_update_loss : 4.08
client: f0279_03
--- local_update_loss : 3.08
client: f1538_15
--- local_update_loss : 3.12
client: f3300_25
--- local_update_loss : 2.35
client: f3701_44
--- local_update_loss : 2.40
client: f1556_19
--- local_update_loss : 2.14
client: f3367_07
--- local_update_loss : 3.19
--- DML_update_loss(A model) with Client:f0733_34: 3.37
--- DML_update_loss(A model) with Client:f2133_68: 3.34
--- DML_update_loss(A model) with Client:f3935_48: 3.50
--- DML_update_loss(A model) with Client:f0496_09: 3.53
--- DML_update_loss(A model) with Client:f1157_43: 3.31
--- DML_update_loss(A model) with Client:f0132_17: 3.37
--- DML_update_loss(A model) with Client:f0337_24: 3.44
--- DML_update_loss(A model) with Client:f2232_76: 3.43
--- DML_update_loss(A model) with Client:f0885_39: 3.44
--- DML_update_loss(A model) with Client:f2500_50: 3.80
--- DML_update_loss(A model) with Client:f3627_46: 3.43
--- DML_update_loss(A model) with Client:f3290_01: 3.46
--- DML_update_loss(A model) with Client:f3315_23: 2.65
--- DML_update_loss(A model) with Client:f1499_12: 2.88
--- DML_update_loss(A model) with Client:f3366_32: 3.56
--- DML_update_loss(A model) with Client:f4092_24: 3.57
--- DML_update_loss(A model) with Client:f0628_05: 3.28
--- DML_update_loss(A model) with Client:f0995_43: 3.56
--- DML_update_loss(A model) with Client:f1869_07: 3.52
--- DML_update_loss(A model) with Client:f0521_14: 3.32
----------- acc -----------
[2.272727272727273, 0.0, 14.285714285714286, 6.451612903225806, 12.5, 7.894736842105263, 11.11111111111111, 6.25, 3.0303030303030303, 3.4482758620689653, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 0.0, 0.0, 0.0, 5.128205128205129, 3.125, 0.0, 8.333333333333334, 0.0, 2.7777777777777777, 2.5641025641025643, 2.7027027027027026, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 2.7027027027027026, 2.4390243902439024, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 0.0, 5.405405405405405, 2.5641025641025643, 0.0, 20.0, 3.8461538461538463, 0.0, 5.2631578947368425, 8.0, 10.0, 0.0, 5.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 10.344827586206897, 9.30232558139535, 5.555555555555555, 0.0, 0.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 12.5, 9.090909090909092, 25.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 0.0, 7.6923076923076925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.333333333333336, 6.25, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 0.0, 16.666666666666668, 0.0, 10.526315789473685, 11.11111111111111, 11.11111111111111, 0.0, 5.882352941176471, 5.882352941176471, 5.555555555555555, 33.333333333333336, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 5.555555555555555, 5.2631578947368425, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 5.555555555555555, 25.0, 0.0, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.18
--- All clients' test acc: 3.92%
2023-04-22 09:12:51,329 [MainThread] [INFO ]  Server train time: 42.58269810676575
2023-04-22 09:12:51,330 [MainThread] [INFO ]  
-------- round 23 --------
2023-04-22 09:12:51,330 [MainThread] [INFO ]  --- start training ---
client: f3841_01
--- local_update_loss : 2.34
client: f1231_36
--- local_update_loss : 3.52
client: f1695_12
--- local_update_loss : 3.23
client: f3435_24
--- local_update_loss : 3.14
client: f1392_44
--- local_update_loss : 3.09
client: f0928_42
--- local_update_loss : 3.95
client: f2322_80
--- local_update_loss : 2.41
client: f1616_04
--- local_update_loss : 2.78
client: f1519_36
--- local_update_loss : 3.22
client: f0898_29
--- local_update_loss : 3.27
client: f3618_26
--- local_update_loss : 3.20
client: f3938_46
--- local_update_loss : 3.13
client: f0995_43
--- local_update_loss : 3.38
client: f1435_38
--- local_update_loss : 3.21
client: f0869_20
--- local_update_loss : 2.36
client: f2271_86
--- local_update_loss : 3.55
client: f3362_03
--- local_update_loss : 3.07
client: f3627_46
--- local_update_loss : 3.20
client: f1063_36
--- local_update_loss : 3.44
client: f3717_48
--- local_update_loss : 3.06
--- DML_update_loss(A model) with Client:f3490_39: 3.66
--- DML_update_loss(A model) with Client:f3350_11: 3.69
--- DML_update_loss(A model) with Client:f1157_43: 3.29
--- DML_update_loss(A model) with Client:f1758_36: 3.33
--- DML_update_loss(A model) with Client:f3193_08: 3.47
--- DML_update_loss(A model) with Client:f0733_34: 3.38
--- DML_update_loss(A model) with Client:f4064_46: 3.40
--- DML_update_loss(A model) with Client:f2275_90: 2.74
--- DML_update_loss(A model) with Client:f3297_22: 2.75
--- DML_update_loss(A model) with Client:f0994_46: 3.28
--- DML_update_loss(A model) with Client:f1663_13: 3.50
--- DML_update_loss(A model) with Client:f3566_36: 3.49
--- DML_update_loss(A model) with Client:f0238_02: 3.46
--- DML_update_loss(A model) with Client:f3948_41: 3.82
--- DML_update_loss(A model) with Client:f1618_39: 3.43
--- DML_update_loss(A model) with Client:f0885_39: 3.45
--- DML_update_loss(A model) with Client:f2238_86: 3.23
--- DML_update_loss(A model) with Client:f0745_35: 3.36
--- DML_update_loss(A model) with Client:f3953_28: 2.73
--- DML_update_loss(A model) with Client:f3529_11: 3.56
----------- acc -----------
[2.272727272727273, 0.0, 14.285714285714286, 6.451612903225806, 12.5, 7.894736842105263, 11.11111111111111, 6.25, 3.0303030303030303, 3.4482758620689653, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 0.0, 0.0, 0.0, 5.128205128205129, 3.125, 0.0, 8.333333333333334, 0.0, 2.7777777777777777, 2.5641025641025643, 2.7027027027027026, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 10.81081081081081, 0.0, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 6.0606060606060606, 5.405405405405405, 7.6923076923076925, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 10.0, 0.0, 5.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 10.344827586206897, 9.30232558139535, 5.555555555555555, 0.0, 0.0, 0.0, 3.125, 0.0, 0.0, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.090909090909092, 25.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 11.764705882352942, 7.6923076923076925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 33.333333333333336, 6.25, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 17.647058823529413, 0.0, 0.0, 5.882352941176471, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 0.0, 16.666666666666668, 0.0, 10.526315789473685, 16.666666666666668, 11.11111111111111, 0.0, 5.882352941176471, 11.764705882352942, 5.555555555555555, 33.333333333333336, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 5.555555555555555, 5.2631578947368425, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 5.555555555555555, 25.0, 18.181818181818183, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.19
--- All clients' test acc: 4.12%
2023-04-22 09:13:30,666 [MainThread] [INFO ]  Server train time: 39.33558535575867
2023-04-22 09:13:30,667 [MainThread] [INFO ]  
-------- round 24 --------
2023-04-22 09:13:30,667 [MainThread] [INFO ]  --- start training ---
client: f3435_24
--- local_update_loss : 3.14
client: f2503_57
--- local_update_loss : 2.31
client: f2232_76
--- local_update_loss : 3.03
client: f0277_33
--- local_update_loss : 3.54
client: f3776_05
--- local_update_loss : 3.23
client: f0046_20
--- local_update_loss : 3.08
client: f2412_86
--- local_update_loss : 3.05
client: f4043_08
--- local_update_loss : 2.31
client: f1301_47
--- local_update_loss : 3.51
client: f1618_39
--- local_update_loss : 2.89
client: f2069_42
--- local_update_loss : 3.16
client: f3627_46
--- local_update_loss : 3.15
client: f1439_27
--- local_update_loss : 3.41
client: f3817_22
--- local_update_loss : 3.02
client: f3948_41
--- local_update_loss : 3.64
client: f0180_29
--- local_update_loss : 3.05
client: f1089_04
--- local_update_loss : 3.55
client: f3618_26
--- local_update_loss : 3.18
client: f1679_05
--- local_update_loss : 3.61
client: f2517_63
--- local_update_loss : 3.14
--- DML_update_loss(A model) with Client:f3399_09: 2.67
--- DML_update_loss(A model) with Client:f4064_46: 3.46
--- DML_update_loss(A model) with Client:f2275_90: 2.75
--- DML_update_loss(A model) with Client:f2561_89: 3.62
--- DML_update_loss(A model) with Client:f3717_48: 3.35
--- DML_update_loss(A model) with Client:f0869_20: 3.52
--- DML_update_loss(A model) with Client:f0496_09: 3.54
--- DML_update_loss(A model) with Client:f1997_00: 2.70
--- DML_update_loss(A model) with Client:f1649_03: 3.88
--- DML_update_loss(A model) with Client:f3300_25: 2.73
--- DML_update_loss(A model) with Client:f0337_24: 3.44
--- DML_update_loss(A model) with Client:f0898_29: 3.46
--- DML_update_loss(A model) with Client:f1491_42: 3.28
--- DML_update_loss(A model) with Client:f0292_16: 3.51
--- DML_update_loss(A model) with Client:f3804_08: 2.94
--- DML_update_loss(A model) with Client:f2241_88: 3.85
--- DML_update_loss(A model) with Client:f3297_22: 2.72
--- DML_update_loss(A model) with Client:f3758_19: 3.87
--- DML_update_loss(A model) with Client:f3666_48: 3.47
--- DML_update_loss(A model) with Client:f3490_39: 3.66
----------- acc -----------
[2.272727272727273, 0.0, 14.285714285714286, 6.451612903225806, 12.5, 7.894736842105263, 11.11111111111111, 6.25, 3.0303030303030303, 3.4482758620689653, 7.894736842105263, 2.9411764705882355, 2.6315789473684212, 0.0, 4.444444444444445, 2.5, 2.380952380952381, 0.0, 2.272727272727273, 0.0, 0.0, 5.128205128205129, 3.125, 0.0, 8.333333333333334, 0.0, 2.7777777777777777, 2.5641025641025643, 2.7027027027027026, 0.0, 0.0, 6.0606060606060606, 0.0, 5.0, 5.555555555555555, 2.7777777777777777, 9.75609756097561, 10.81081081081081, 0.0, 3.3333333333333335, 3.225806451612903, 0.0, 0.0, 5.2631578947368425, 0.0, 6.0606060606060606, 8.108108108108109, 7.6923076923076925, 0.0, 20.0, 3.8461538461538463, 0.0, 2.6315789473684212, 8.0, 10.0, 0.0, 5.0, 0.0, 0.0, 0.0, 3.8461538461538463, 0.0, 10.344827586206897, 9.30232558139535, 5.555555555555555, 0.0, 0.0, 0.0, 3.125, 0.0, 6.451612903225806, 7.142857142857143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 12.5, 0.0, 0.0, 9.090909090909092, 25.0, 0.0, 5.882352941176471, 6.25, 0.0, 11.11111111111111, 0.0, 13.333333333333334, 11.764705882352942, 7.6923076923076925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 0.0, 0.0, 33.333333333333336, 6.25, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 17.647058823529413, 0.0, 0.0, 17.647058823529413, 0.0, 0.0, 0.0, 5.882352941176471, 11.11111111111111, 0.0, 0.0, 0.0, 5.882352941176471, 0.0, 11.11111111111111, 0.0, 0.0, 0.0, 0.0, 0.0, 11.764705882352942, 5.882352941176471, 0.0, 16.666666666666668, 0.0, 10.526315789473685, 11.11111111111111, 11.11111111111111, 0.0, 5.882352941176471, 11.764705882352942, 5.555555555555555, 33.333333333333336, 5.555555555555555, 0.0, 0.0, 0.0, 16.666666666666668, 5.882352941176471, 5.882352941176471, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.882352941176471, 11.764705882352942, 5.555555555555555, 5.2631578947368425, 11.764705882352942, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 0.0, 17.647058823529413, 0.0, 5.882352941176471, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 11.764705882352942, 0.0, 5.555555555555555, 0.0, 0.0, 0.0, 5.555555555555555, 0.0, 9.090909090909092, 0.0]
--------- test avarage ---------
--- All clients' test loss: 4.20
--- All clients' test acc: 4.22%
2023-04-22 09:14:11,200 [MainThread] [INFO ]  Server train time: 40.532426834106445
2023-04-22 09:14:11,201 [MainThread] [INFO ]  
-------- round 25 --------
2023-04-22 09:14:11,201 [MainThread] [INFO ]  --- start training ---
client: f3826_07
--- local_update_loss : 3.45
client: f2232_76
--- local_update_loss : 3.00
client: f0385_18
--- local_update_loss : 3.99
client: f3519_18
--- local_update_loss : 4.05
client: f3490_39
--- local_update_loss : 3.40
client: f3219_49
--- local_update_loss : 3.15
client: f3368_37
--- local_update_loss : 3.26
client: f3399_09
--- local_update_loss : 2.32
client: f2503_57
--- local_update_loss : 2.31
client: f0547_28
--- local_update_loss : 4.12
client: f1696_08
--- local_update_loss : 3.56
client: f0522_38
--- local_update_loss : 3.32
client: f2076_31
--- local_update_loss : 3.63
client: f1491_42
--- local_update_loss : 3.16
client: f1231_36
--- local_update_loss : 3.51
client: f0867_28
--- local_update_loss : 3.59
client: f1439_27
--- local_update_loss : 3.41
client: f1663_13
--- local_update_loss : 3.25
client: f0496_09
--- local_update_loss : 3.40
client: f1677_01
--- local_update_loss : 2.36
--- DML_update_loss(A model) with Client:f1431_47: 3.05
--- DML_update_loss(A model) with Client:f3751_39: 3.81
--- DML_update_loss(A model) with Client:f3953_28: 2.72
--- DML_update_loss(A model) with Client:f3566_36: 3.51
--- DML_update_loss(A model) with Client:f1519_36: 3.47
--- DML_update_loss(A model) with Client:f4000_40: 3.28
--- DML_update_loss(A model) with Client:f0781_31: 3.58
--- DML_update_loss(A model) with Client:f2312_87: 2.73
Traceback (most recent call last):
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/main/femnist/main.py", line 19, in <module>
    easyfl.run()
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/coordinator.py", line 390, in run
    _global_coord.run()
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/coordinator.py", line 80, in run
    self.server.start(self.model, self.clients)
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/server/base.py", line 164, in start
    self.train()
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/server/base.py", line 200, in train
    self.distribution_to_train()
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/server/base.py", line 347, in distribution_to_train
    self.distribution_to_train_locally()
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/main/femnist/CustomizeServer.py", line 91, in distribution_to_train_locally
    client.run_train(model, self.conf.client, train_local_only=False)
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/main/femnist/CustomizedClient.py", line 154, in run_train
    self.train(conf, self.device, train_local_only) # 
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/main/femnist/CustomizedClient.py", line 142, in train
    self.train_DML(conf, device)
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/easyfl/main/femnist/CustomizedClient.py", line 63, in train_DML
    model_A = copy.deepcopy(self.model)
  File "/usr/lib/python3.10/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File "/usr/lib/python3.10/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
  File "/usr/lib/python3.10/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/usr/lib/python3.10/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/usr/lib/python3.10/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File "/usr/lib/python3.10/copy.py", line 297, in _reconstruct
    value = deepcopy(value, memo)
  File "/usr/lib/python3.10/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File "/usr/lib/python3.10/copy.py", line 271, in _reconstruct
    state = deepcopy(state, memo)
  File "/usr/lib/python3.10/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/usr/lib/python3.10/copy.py", line 231, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/usr/lib/python3.10/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File "/usr/lib/python3.10/copy.py", line 297, in _reconstruct
    value = deepcopy(value, memo)
  File "/usr/lib/python3.10/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/home/dengzhiling/.local/lib/python3.10/site-packages/torch/nn/parameter.py", line 55, in __deepcopy__
    result = type(self)(self.data.clone(memory_format=torch.preserve_format), self.requires_grad)
KeyboardInterrupt
